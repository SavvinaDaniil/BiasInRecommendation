{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45373607",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d1fae",
   "metadata": {},
   "source": [
    "I will try (and fail probably) to put everything into one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f3154",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf3cc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from qwikidata.sparql  import return_sparql_query_results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from collections import Counter\n",
    "import urllib.request\n",
    "import json\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fae3d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_to_save = \"data/final_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ade72",
   "metadata": {},
   "source": [
    "# 1. Download all WikiData entries\n",
    "Goal: To download (using SparQL queries) all WikiData entries that have VIAF ids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80789b5c",
   "metadata": {},
   "source": [
    "A. Get all WikiData entries with VIAF ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af61a82",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cec7ce6bc36f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \"\"\"\n\u001b[1;32m      8\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mitems_with_viaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_sparql_query_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# run the query and get results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"It took \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\" seconds.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_environment/lib64/python3.6/site-packages/qwikidata/sparql.py\u001b[0m in \u001b[0;36mreturn_sparql_query_results\u001b[0;34m(query_string, wikidata_sparql_url)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[1;32m     22\u001b[0m     return requests.get(\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mwikidata_sparql_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"format\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     ).json()\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_environment/lib64/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_environment/lib64/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_environment/lib64/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_environment/lib64/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_environment/lib64/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_environment/lib64/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_environment/lib64/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \"\"\"\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_environment/lib64/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_environment/lib64/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\";\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query_string = \"\"\"\n",
    "        SELECT DISTINCT ?item ?viaf # return QID and VIAF ID\n",
    "WHERE \n",
    "{ ?item wdt:P214 ?viaf. # select all the items in WikiData that have VIAF ID\n",
    "\n",
    "}\n",
    "        \"\"\"\n",
    "start = time.time()\n",
    "items_with_viaf = return_sparql_query_results(query_string) # run the query and get results\n",
    "print(\"It took \"+str(np.round(time.time()-start,2))+ \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b43e6",
   "metadata": {},
   "source": [
    "B. Process results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_with_viaf = pd.DataFrame(items_with_viaf[\"results\"][\"bindings\"])\n",
    "items_with_viaf[\"item\"] = items_with_viaf[\"item\"].apply(lambda x: x[\"value\"].split(\"/\")[-1]) # keep only QID\n",
    "items_with_viaf[\"viaf\"] = items_with_viaf[\"viaf\"].apply(lambda x: x[\"value\"]) # keep only VIAF ID\n",
    "items_with_viaf.columns = [\"QID\", \"viaf_id\"] # rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e00b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_with_viaf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In WikiData, there are \"+str(len(items_with_viaf))+\" items with VIAF ID.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ddbf5a",
   "metadata": {},
   "source": [
    "C. Save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save with Pickle\n",
    "with open(location_to_save + \"items_with_viaf_wikidata.pkl\", \"wb\") as output_file:\n",
    "    pkl.dump(items_with_viaf, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba2ab3a",
   "metadata": {},
   "source": [
    "# 2. Recreate Fairbook dataset\n",
    "Goal: To cut down the dataset the same way that they did in FairBook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaded2b",
   "metadata": {},
   "source": [
    "A. Read files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1fb9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/ratings_books.csv\", low_memory=False).fillna(\"\")\n",
    "dataset.columns = ['User-ID', 'ISBN', 'Book-Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb5a3ea",
   "metadata": {},
   "source": [
    "B. Print statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "693c576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset statistics: \n",
      "> No. of users: 105283\n",
      "> No. of Books: 340556\n",
      "> No. of Interaction: 1149780\n"
     ]
    }
   ],
   "source": [
    "print(\"Original dataset statistics: \")\n",
    "print(f\"> No. of users: {len(dataset['User-ID'].unique())}\")\n",
    "print(f\"> No. of Books: {len(dataset['ISBN'].unique())}\")\n",
    "print(f\"> No. of Interaction: {dataset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac56cb7d",
   "metadata": {},
   "source": [
    "C. Filter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58ba0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rows_by_values(df, col, values):\n",
    "    return df[~df[col].isin(values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4af1b9",
   "metadata": {},
   "source": [
    "C.1. Remove implicit (i.e. 0) ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c2ba106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit dataset statistics: \n",
      "> No. of users: 77805\n",
      "> No. of Books: 185973\n",
      "> No. of Interaction: 433671\n"
     ]
    }
   ],
   "source": [
    "dataset = filter_rows_by_values(dataset, \"Book-Rating\", [0])\n",
    "\n",
    "# statistics on explicit dataset\n",
    "print(\"Explicit dataset statistics: \")\n",
    "print(f\"> No. of users: {len(dataset['User-ID'].unique())}\")\n",
    "print(f\"> No. of Books: {len(dataset['ISBN'].unique())}\")\n",
    "print(f\"> No. of Interaction: {dataset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cee96",
   "metadata": {},
   "source": [
    "C.2. Remove:\n",
    "1. Users with more than 200 ratings\n",
    "2. Users with less than 5 rarings\n",
    "3. Items with less than 5 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d450b56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of users with more than 200 interactions: 144\n"
     ]
    }
   ],
   "source": [
    "# To check if there is any user with more than 200 interaction in the preprocessed dataset\n",
    "# The correct output will be zero\n",
    "uid_value_counts = dataset['User-ID'].value_counts()\n",
    "print(\"The number of users with more than 200 interactions:\", len(uid_value_counts[uid_value_counts > 200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b58c689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove the users with fewer than 5 interaction we first count the number of interactino per user and add a new column (`Count`) in the dataframe.\n",
    "# This column shows the number of interaction per user in the dataset\n",
    "users_counts = dataset['User-ID'].value_counts()\n",
    "users_counts = users_counts.to_dict() #converts to dictionary\n",
    "dataset['Count'] = dataset['User-ID'].map(users_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e3642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = filter_rows_by_values(dataset, \"Count\", list(range(200, max(dataset['Count']) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5496bad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset statistics (users with interactions < 200): \n",
      "> No. of users: 77660\n",
      "> No. of Books: 156891\n",
      "> No. of Interaction: 364245\n"
     ]
    }
   ],
   "source": [
    "# statistics on explicit dataset after removing users with more than 200 int.\n",
    "print(f\"New dataset statistics (users with interactions < {200}): \")\n",
    "print(f\"> No. of users: {len(dataset['User-ID'].unique())}\")\n",
    "print(f\"> No. of Books: {len(dataset['ISBN'].unique())}\")\n",
    "print(f\"> No. of Interaction: {dataset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c5dbe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 63585\n",
      "No. of items < 5 ineractions: 119254\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 5825\n",
      "No. of items < 5 ineractions: 1594\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 432\n",
      "No. of items < 5 ineractions: 208\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 69\n",
      "No. of items < 5 ineractions: 45\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 19\n",
      "No. of items < 5 ineractions: 17\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 11\n",
      "No. of items < 5 ineractions: 13\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 6\n",
      "No. of items < 5 ineractions: 2\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 2\n",
      "No. of items < 5 ineractions: 4\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 1\n",
      "No. of items < 5 ineractions: 1\n",
      "The current number of user and item with < 5 interactions: \n",
      "No. of users < 5 ineractions: 0\n",
      "No. of items < 5 ineractions: 0\n"
     ]
    }
   ],
   "source": [
    "user_interaction, item_interaction = 1, 1\n",
    "\n",
    "while user_interaction != 0 or item_interaction != 0:\n",
    "    print(f\"The current number of user and item with < 5 interactions: \")\n",
    "    # user side fewer than ds_rate cheking\n",
    "    uid_value_counts = dataset['User-ID'].value_counts()\n",
    "    user_interaction = uid_value_counts[uid_value_counts < 5].count()\n",
    "    print(f\"No. of users < 5 ineractions: {user_interaction}\")\n",
    "\n",
    "    users_counts = dataset['User-ID'].value_counts()\n",
    "    users_counts = users_counts.to_dict() #converts to dictionary\n",
    "    dataset['Count'] = dataset['User-ID'].map(users_counts)\n",
    "\n",
    "    dataset = filter_rows_by_values(dataset, \"Count\", list(range(5)))\n",
    "\n",
    "    # item side fewer than ds_rate cheking\n",
    "    bid_value_counts = dataset['ISBN'].value_counts()\n",
    "    item_interaction = bid_value_counts[bid_value_counts < 5].count()\n",
    "    print(f\"No. of items < 5 ineractions: {item_interaction}\")\n",
    "\n",
    "    items_counts = dataset['ISBN'].value_counts()\n",
    "    items_counts = items_counts.to_dict() #converts to dictionary\n",
    "    dataset['Count'] = dataset['ISBN'].map(items_counts)\n",
    "\n",
    "    dataset = filter_rows_by_values(dataset, \"Count\", list(range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34797129",
   "metadata": {},
   "source": [
    "D. Print statistics after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41c44750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of users: 6358\n",
      "No. of Books: 6921\n",
      "No. of Interaction: 88552\n"
     ]
    }
   ],
   "source": [
    "# statistics on 5 rate explicit dataset (after pre-processing)\n",
    "print(f\"No. of users: {len(dataset['User-ID'].unique())}\")\n",
    "print(f\"No. of Books: {len(dataset['ISBN'].unique())}\")\n",
    "print(f\"No. of Interaction: {dataset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b461efca",
   "metadata": {},
   "source": [
    "E. Save file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "566c1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we save the preprocessed explicit dataset (5Rate) we first remove the added column which is `Count`\n",
    "del dataset['Count']\n",
    "dataset.to_csv(location_to_save+\"fairbook_ratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebdb7a",
   "metadata": {},
   "source": [
    "# 3. First look in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10f6b5",
   "metadata": {},
   "source": [
    "A. Read book file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0c80ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/items_books.csv\" # Books-Crossing books\n",
    "books = pd.read_csv(filename, low_memory = False).drop([\"Image-URL-S\", \"Image-URL-M\",\"Image-URL-L\"], axis=1) # read books and remove images\n",
    "books.columns = [\"ISBN\", \"title\", \"author\", \"year\", \"publisher\"] # rename columns to simplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "346b99c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 271360 books.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \"+str(len(books))+\" books.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad138458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                              title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                 author  year                   publisher  \n",
       "0    Mark P. O. Morford  2002     Oxford University Press  \n",
       "1  Richard Bruce Wright  2001       HarperFlamingo Canada  \n",
       "2          Carlo D'Este  1991             HarperPerennial  \n",
       "3      Gina Bari Kolata  1999        Farrar Straus Giroux  \n",
       "4       E. J. W. Barber  1999  W. W. Norton &amp; Company  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2a111",
   "metadata": {},
   "source": [
    "B. Choose \"unique\" authors based on exact author name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdee6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = pd.DataFrame(books.author.unique(), columns=[\"author\"]).dropna().reset_index().drop(\"index\", axis=1) # find unique authors and remove nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34bb433f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 102023 unique authors.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \"+str(len(authors))+\" unique authors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a22bad9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carlo D'Este</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E. J. W. Barber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author\n",
       "0    Mark P. O. Morford\n",
       "1  Richard Bruce Wright\n",
       "2          Carlo D'Este\n",
       "3      Gina Bari Kolata\n",
       "4       E. J. W. Barber"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40377263",
   "metadata": {},
   "source": [
    "C. Statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ce0d0",
   "metadata": {},
   "source": [
    "C.1 Non-latin named authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49960e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s): # function to check if a name is latin\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f3f2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors[\"author_latin\"] = authors.author.apply(lambda x : isEnglish(x))\n",
    "num_latin_authors = len(authors[authors.author_latin == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e39f91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  100642 latin authors out of 102023.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \", num_latin_authors,\"latin authors out of\", str(len(authors))+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96e7fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "del authors[\"author_latin\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908cf47",
   "metadata": {},
   "source": [
    "C.2 Author entries with a single name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5850e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors[\"author_single\"] = authors.author.apply(lambda x: len(x.split(\" \"))==1)\n",
    "num_single_named_authors = len(authors[authors.author_single == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "219a0448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  2502 single named authors out of 102023.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \", num_single_named_authors,\"single named authors out of\", str(len(authors))+\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2317d9b6",
   "metadata": {},
   "source": [
    "# 4. Access Google Books API\n",
    "Goal: To use the ISBNs from the dataset to get the author and title of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6228aae",
   "metadata": {},
   "source": [
    "A. Function to access the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89072856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_title(ISBN):\n",
    "    base_api_link = \"https://www.googleapis.com/books/v1/volumes?q=isbn:\"\n",
    "\n",
    "        \n",
    "    with urllib.request.urlopen(base_api_link + ISBN) as f:\n",
    "        text = f.read()\n",
    "    decoded_text = text.decode(\"utf-8\")\n",
    "    obj = json.loads(decoded_text) # deserializes decoded_text to a Python object\n",
    "    try:\n",
    "        volume_info = obj[\"items\"][0] \n",
    "    except: \n",
    "        \n",
    "        #print(obj)\n",
    "        return(\"\",\"\")\n",
    "    title = volume_info[\"volumeInfo\"][\"title\"]\n",
    "    try:\n",
    "        authors = volume_info[\"volumeInfo\"][\"authors\"]\n",
    "        \n",
    "    except:\n",
    "        #print(volume_info[\"volumeInfo\"])\n",
    "        return(\"\",title)\n",
    "\n",
    "    return(authors,title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d0f6a",
   "metadata": {},
   "source": [
    "B. Initialize the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d102f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "books[\"alt_title\"] = \"\"\n",
    "books[\"alt_author\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2145786e",
   "metadata": {},
   "source": [
    "C. Run the requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fba026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006394386291503906 0\n",
      "SAVE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "13.718112707138062 100\n",
      "5.526361465454102 200\n",
      "9.197191715240479 300\n",
      "7.610250473022461 400\n",
      "5.588155031204224 500\n",
      "5.983975648880005 600\n",
      "6.799439191818237 700\n",
      "6.232158184051514 800\n",
      "7.780362367630005 900\n",
      "11.714506149291992 1000\n",
      "SAVE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "54.44746661186218 1100\n",
      "51.574361085891724 1200\n",
      "52.19705271720886 1300\n",
      "58.07039713859558 1400\n",
      "57.98281526565552 1500\n",
      "54.422123670578 1600\n",
      "51.33484077453613 1700\n",
      "57.65367865562439 1800\n",
      "66.69387125968933 1900\n",
      "57.62889838218689 2000\n",
      "SAVE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "57.32115864753723 2100\n",
      "54.908679723739624 2200\n",
      "58.367151975631714 2300\n",
      "56.00740671157837 2400\n",
      "57.03478121757507 2500\n",
      "62.68689799308777 2600\n",
      "55.46373796463013 2700\n",
      "58.13046598434448 2800\n",
      "61.23895001411438 2900\n",
      "54.17751121520996 3000\n",
      "SAVE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "58.789758920669556 3100\n",
      "53.837313413619995 3200\n",
      "58.452035665512085 3300\n",
      "59.01812744140625 3400\n",
      "59.85523796081543 3500\n",
      "57.868881702423096 3600\n",
      "55.37895727157593 3700\n",
      "60.78868579864502 3800\n",
      "55.65697979927063 3900\n",
      "61.83735466003418 4000\n",
      "SAVE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "57.4927396774292 4100\n",
      "59.52882957458496 4200\n",
      "58.864661693573 4300\n",
      "64.35327434539795 4400\n",
      "61.352944135665894 4500\n",
      "53.210856914520264 4600\n",
      "56.39782643318176 4700\n",
      "58.2767059803009 4800\n",
      "58.90170645713806 4900\n",
      "54.209248542785645 5000\n",
      "SAVE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "61.67442297935486 5100\n",
      "60.969157695770264 5200\n",
      "59.86530065536499 5300\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for index,row in books.iterrows():\n",
    "    if row[\"alt_author\"]==\"\":\n",
    "        ISBN = row[\"ISBN\"]\n",
    "        statement = True\n",
    "        i=0\n",
    "        while statement:\n",
    "            \n",
    "            try:\n",
    "                authors, title = get_author_title(ISBN)\n",
    "                statement = False\n",
    "            except:\n",
    "                if i>50:\n",
    "                    statement = False\n",
    "                    print(\"IT FAILED MORE THAN 50 TIMES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                time.sleep(0.1)\n",
    "            i+=1  \n",
    "            \n",
    "        if type(authors)==list:\n",
    "            authors = \"|\".join(authors)\n",
    "        books.at[index, \"alt_title\"] = title\n",
    "        books.at[index, \"alt_author\"] = authors\n",
    "    if index%100==0:\n",
    "        print(time.time()-start, index)\n",
    "        start = time.time()\n",
    "        time.sleep(5)\n",
    "        if index%1000==0:\n",
    "            print(\"SAVE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            books.to_csv(location_to_save+\"items_books_some_isbn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ba26a",
   "metadata": {},
   "source": [
    "# 5. Analyze results from Google Books API\n",
    "Goal: To check the structure and completeness of the Google Books information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6086fabf",
   "metadata": {},
   "source": [
    "<b>A. Read file.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd2f04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(location_to_save + \"items_books_some_isbn.csv\", low_memory = False, index_col=0).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "635f02dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>alt_title</th>\n",
       "      <th>alt_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford|Robert J. Lenardon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>Flu</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>The Mummies of Ürümchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                              title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                 author  year                   publisher  \\\n",
       "0    Mark P. O. Morford  2002     Oxford University Press   \n",
       "1  Richard Bruce Wright  2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este  1991             HarperPerennial   \n",
       "3      Gina Bari Kolata  1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber  1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                alt_title                             alt_author  \n",
       "0     Classical Mythology  Mark P. O. Morford|Robert J. Lenardon  \n",
       "1            Clara Callan                   Richard Bruce Wright  \n",
       "2    Decision in Normandy                           Carlo D'Este  \n",
       "3                     Flu                       Gina Bari Kolata  \n",
       "4  The Mummies of Ürümchi                        E. J. W. Barber  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dc3f09",
   "metadata": {},
   "source": [
    "<b>B. Check completeness.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e3246f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_results_authors = len(books[(books.alt_author==\"\")].drop_duplicates(subset = \"author\"))\n",
    "no_results_books = len(books[(books.alt_author==\"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a6c7036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 70797 unique authors, we couldn't match the ISBN of at least one of their books, out of 102024 authors.\n",
      "For 141219 books, we couldn't match the ISBN, out of 271360 books.\n"
     ]
    }
   ],
   "source": [
    "print(\"For\", no_results_authors,\"unique authors, we couldn't match the ISBN of at least one of their books, out of\",len(books.drop_duplicates(subset = \"author\")), \"authors.\")\n",
    "print(\"For\", no_results_books,\"books, we couldn't match the ISBN, out of\", len(books), \"books.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77456da8",
   "metadata": {},
   "source": [
    "<b>C. Compare Book-Crossing with Google Books.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e45d2",
   "metadata": {},
   "source": [
    "<b>C.1 First estimation: Naive. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ad3f09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At first glance, we didn't find the same author for 179523 books out of  271360. However, it needs more processing.\n"
     ]
    }
   ],
   "source": [
    "first_estimation = len(books[books.author!=books.alt_author])\n",
    "print(\"At first glance, we didn't find the same author for\", first_estimation,\"books out of \",str(len(books))+\". However, it needs more processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c6ec8",
   "metadata": {},
   "source": [
    "<b>C.2 Second estimation: Simplify author names.</b>\n",
    "\n",
    "We need a function that:\n",
    "1. Removes spaces\n",
    "2. Removes punctuation\n",
    "3. Makes lowercase\n",
    "\n",
    "<b>This way, we can more properly compare the strings.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf59e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(name):\n",
    "    name = name.replace(\" \",\"\").translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3b1c142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvinagdaniil'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplify(\"Savvina G. Daniil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14d5ba",
   "metadata": {},
   "source": [
    "We create a column called \"correct_author\" where we replace it with the alt_author if simplified it is the same as the book crossing author. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84ef3dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "books[\"correct_author\"] = ''\n",
    "for index,row in books.iterrows():\n",
    "    if row.alt_author!=\"\":\n",
    "        if simplify(row.author)==simplify(row.alt_author):\n",
    "            books.at[index, \"correct_author\"] = row.alt_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c8e7b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the simplifying, we didn't find the same author for 173947 books out of  271360. However, it needs even more processing.\n"
     ]
    }
   ],
   "source": [
    "second_estimation = len(books[books.correct_author==\"\"])\n",
    "print(\"With the simplifying, we didn't find the same author for\", second_estimation,\"books out of \",str(len(books))+\". However, it needs even more processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5526b",
   "metadata": {},
   "source": [
    "#### C.3 Third estimation: Account for multiple authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848c384",
   "metadata": {},
   "source": [
    "Since in alt_author we collect all authors, we make sure that we consider if any of them (separated by \"|\") is the same as author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e7a443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in books.iterrows():\n",
    "    if row.correct_author==\"\": # only if we haven't already found the correct author of that book\n",
    "        if row.alt_author!=\"\": # if we got ISBN result\n",
    "            alt_author = row.alt_author\n",
    "            bag_of_alt_authors = alt_author.split(\"|\")\n",
    "            simplified_bag_of_alt_authors = [simplify(x) for x in bag_of_alt_authors]\n",
    "            author = simplify(row.author)\n",
    "            for i in range(len(bag_of_alt_authors)):\n",
    "                if author==simplified_bag_of_alt_authors[i]:\n",
    "                    books.at[index, \"correct_author\"] = bag_of_alt_authors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0a609b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With accounting for bag of authors, we didn't find the same author for 159867 books out of  271360. However, it needs even more processing.\n"
     ]
    }
   ],
   "source": [
    "third_estimation = len(books[books.correct_author==\"\"])\n",
    "print(\"With accounting for bag of authors, we didn't find the same author for\", third_estimation,\"books out of \",str(len(books))+\". However, it needs even more processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293c26b",
   "metadata": {},
   "source": [
    "#### C.4 Fourth estimation: Reverse names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969e0ba1",
   "metadata": {},
   "source": [
    "I noticed that some names are reversed, e.g. Charles Glass and Glass Charles are not considered the same name by my processing. So I add an extra layer: sort the characters of the name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe2c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd7977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
