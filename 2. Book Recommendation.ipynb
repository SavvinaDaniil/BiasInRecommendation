{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdmWUJCl6USJ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SavvinaDaniil/BiasInRecommendation/blob/main/Book%20recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZEwzP5d6USR"
      },
      "source": [
        "This notebook should be run on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCeSb4Vu6USS"
      },
      "source": [
        "# Process\n",
        "In this notebook, I will train the book recommendation algorithms using two different packages: <a href=\"http://surpriselib.com/\">Surprise</a> & <a href=\"https://cornac.readthedocs.io/en/latest/\">Cornac</a>. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7QlcgcE6USU"
      },
      "source": [
        "## A. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPmwTeS66USV",
        "outputId": "63d3e214-46a6-4800-873c-4def9f8af2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cornac in /usr/local/lib/python3.7/dist-packages (1.14.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cornac) (1.4.1)\n",
            "Requirement already satisfied: powerlaw in /usr/local/lib/python3.7/dist-packages (from cornac) (1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cornac) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from cornac) (4.63.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from powerlaw->cornac) (3.2.2)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from powerlaw->cornac) (1.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->powerlaw->cornac) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->powerlaw->cornac) (1.15.0)\n",
            "Requirement already satisfied: surprise in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.7/dist-packages (from surprise) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.21.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install cornac\n",
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "47V5DR7s6USa"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#from run_algorithms import train_algorithms, train_algorithms_kf, prepare_dataset, prepare_dataset_kf\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "pd.set_option(\"display.precision\", 6)\n",
        "\n",
        "# Cornac imports\n",
        "import cornac\n",
        "from cornac.eval_methods import RatioSplit\n",
        "from cornac.data import Reader as CornacReader #Reader exists in both packages\n",
        "from cornac.models import MostPop, MF, PMF, BPR, NeuMF, WMF, HPF, VAECF, NMF\n",
        "from cornac.models import NMF as CornacNMF #NMF exists in both packages\n",
        "from cornac.metrics import MAE, MSE, RMSE, Precision, Recall, NDCG, AUC, MAP, FMeasure, MRR\n",
        "\n",
        "from surprise import BaselineOnly, KNNBasic, KNNWithMeans, SVDpp, SVD\n",
        "from surprise import NMF as SurpriseNMF #NMF exists in both packages\n",
        "from surprise import Dataset\n",
        "from surprise import Reader as SurpriseReader #Reader exists in both packages\n",
        "from surprise.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from surprise import accuracy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from collections import defaultdict\n",
        "from scipy import stats\n",
        "from numpy.linalg import norm\n",
        "import seaborn as sns\n",
        "# set plot style: grey grid in the background:\n",
        "sns.set(style=\"darkgrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxc749MS6USc"
      },
      "source": [
        "## B. Set hyperparameters\n",
        "There are certain hyperparameters that need to be tuned before the run. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KpDdroKt6USd"
      },
      "outputs": [],
      "source": [
        "item_threshold = 5 # remove users with less than item_threshold items\n",
        "user_threshold = 5 # remove items with less than user_threshold users\n",
        "top_threshold = 200 # remove users who have rated more than top_threshold items\n",
        "recommendation_type = \"books\" # books, music or movies\n",
        "item_col = \"book\" # the item column\n",
        "my_seed = 0 # random_seed\n",
        "top_fraction_items = 0.2 # the limit for an item to be considered popular\n",
        "top_fraction_users = 0.2# the limit for a user to be considered High Mainstriminess\n",
        "split_by = \"pop_fraq\" # sort users by fraction of popular items (pop_fraq) or by average popularity in profile (pop_item_fraq)\n",
        "test_size = 0.2 # the percentage of \"hold out\" data that are used for testing\n",
        "rating_threshold = 1.0 # needed for the cornac library\n",
        "predict_col = \"rating\" # the column we are predicting\n",
        "train_way = \"simple_split\"\n",
        "n_splits = 5 # the amount of splits\n",
        "\n",
        "if train_way == \"simple_split\": n_splits = 1\n",
        "rd.seed(my_seed)\n",
        "np.random.seed(my_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSnYGMbb6USg"
      },
      "source": [
        "These additions will be useful so we can load and save the different files (plots and processed data) with clarity on the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oYgsM9m86USh"
      },
      "outputs": [],
      "source": [
        "addition_1 = \"_u\"+str(item_threshold)+\"_i\"+str(user_threshold)+\"_t\"+str(top_threshold)\n",
        "addition_2 = addition_1 + \"_tfi\"+str(int(100*top_fraction_items))\n",
        "addition_3 = addition_2 + \"_tfu\"+str(int(100*top_fraction_users))\n",
        "addition_4 = addition_3 + (\"_sbpf\" if (split_by==\"pop_fraq\") else \"_sbpif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbqK-CH56USj"
      },
      "source": [
        "## C. Read files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "utMWqIUK6USk"
      },
      "outputs": [],
      "source": [
        "user_events_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/ratings\"+addition_1+\".csv\"\n",
        "high_user_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/high_users\"+addition_4+\".csv\"\n",
        "low_user_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/low_users\"+addition_4+\".csv\"\n",
        "medium_user_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/med_users\"+addition_4+\".csv\"\n",
        "df_item_dist_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/item_pop_dist\"+addition_1+\".csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ6FsCRR6USl",
        "outputId": "4e3a8d6c-73a6-45f3-ea03-fb092fb0486e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "os.system(\"wget \"+user_events_file)\n",
        "os.system(\"wget \"+low_user_file)\n",
        "os.system(\"wget \"+high_user_file)\n",
        "os.system(\"wget \"+medium_user_file)\n",
        "os.system(\"wget \"+df_item_dist_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "low = pd.read_csv(low_user_file, index_col=0)\n",
        "med = pd.read_csv(medium_user_file, index_col=0)\n",
        "high = pd.read_csv(high_user_file, index_col=0)"
      ],
      "metadata": {
        "id": "WsWUflDo8K25"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = len(low) + len(med) + len(high)\n",
        "print(num_users)"
      ],
      "metadata": {
        "id": "RTH6eEdX4sw8",
        "outputId": "73a09f8c-d4cc-4651-f088-0e55da24885f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_item_dist = pd.read_csv(df_item_dist_file, index_col = 0)"
      ],
      "metadata": {
        "id": "pUKKcoUG81fK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH7BETV86USm"
      },
      "source": [
        "## D. Recommendation "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need two df_item_dist: one for Surprise, one for Cornac\n",
        "df_item_dist_Surprise = df_item_dist.copy()\n",
        "df_item_dist_Cornac = df_item_dist.copy()"
      ],
      "metadata": {
        "id": "Rm5kOIQMOUa2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Surprise"
      ],
      "metadata": {
        "id": "1ctrkzpEGyb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_events = pd.read_csv(user_events_file, low_memory = False, header=0) # create dataframe"
      ],
      "metadata": {
        "id": "wGMFHd54JUOh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset in Surprise\n",
        "reader = SurpriseReader(rating_scale=(df_events[predict_col].min(), df_events[predict_col].max()))\n",
        "data = Dataset.load_from_df(df_events, reader)"
      ],
      "metadata": {
        "id": "rmZPcpzaG4dH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split in train and test set\n",
        "trainset, testset = train_test_split(data, test_size = test_size, random_state = my_seed)"
      ],
      "metadata": {
        "id": "mxOL9xlVJ27r"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select and initialize algorithms\n",
        "algo_names = [\"Random\",\n",
        "              \"MostPopular\",\n",
        "              'UserItemAvg',\n",
        "                  'UserKNN',\n",
        "                  'UserKNNAvg',\n",
        "                  'NMF', \n",
        "                  'SVD']\n",
        "\n",
        "# the default parameters for all algorithms\n",
        "algos = [] \n",
        "algos.append(None)#Random())\n",
        "algos.append(None)#MostPopular())\n",
        "algos.append(BaselineOnly()) \n",
        "algos.append(KNNBasic(sim_options = {'name': 'cosine', 'user_based': True})) \n",
        "algos.append(KNNWithMeans(sim_options = {'name': 'cosine', 'user_based': True})) \n",
        "algos.append(SurpriseNMF())\n",
        "algos.append(SVD())"
      ],
      "metadata": {
        "id": "g6M3o5Z8KMlO"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n_Surprise(predictions, n=10):\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "    return top_n"
      ],
      "metadata": {
        "id": "v1t4g_mvPcXB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n_random_Surprise(testset, df_item_dist, n=10):\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r in testset:\n",
        "      if len(top_n[uid]) == 0:\n",
        "        for i in range(0, 10):\n",
        "          top_n[uid].append((rd.choice(df_item_dist.index), i))\n",
        "    \n",
        "    return top_n"
      ],
      "metadata": {
        "id": "7EsIyRzKPrGD"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n_mp_Surprise(testset, item_dist, n=10):\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r in testset:\n",
        "        if len(top_n[uid]) == 0:\n",
        "            for iid, count in df_item_dist[:n][\"count\"].items():\n",
        "                top_n[uid].append((iid, count))\n",
        "    return top_n"
      ],
      "metadata": {
        "id": "EMJz96S5Pvja"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "low_rec_gap_list = [] # one entry per algorithm\n",
        "medium_rec_gap_list = []\n",
        "high_rec_gap_list = []\n",
        "start = time.time()\n",
        "\n",
        "for i in tqdm(range(0, len(algo_names))): # for every algorithm\n",
        "    print(\"~~~~~~~~~~~~~~~~NEW~~~~~~~~~~~~~~~~~\")\n",
        "    df_item_dist_Surprise[algo_names[i]] = 0 # I am adding a column to Surprise\n",
        "    low_rec_gap = 0\n",
        "    medium_rec_gap = 0\n",
        "    high_rec_gap = 0\n",
        "    \n",
        "    # get accuracy for personalized approaches\n",
        "    if algo_names[i] != 'Random' and algo_names[i] != 'MostPopular': # for proper algorithms\n",
        "        algos[i].fit(trainset) # fit\n",
        "        predictions = algos[i].test(testset) # predict\n",
        "        print(algo_names[i]) # end of fitting\n",
        "\n",
        "        #get_mae_of_groups(predictions, low, med, high) TO BE ADDED\n",
        "    \n",
        "    # get top-n items and calculate gaps for all algorithms\n",
        "    if algo_names[i] == 'Random':\n",
        "        top_n = get_top_n_random_Surprise(testset, df_item_dist, n=10)\n",
        "        print(algo_names[i])\n",
        "    elif algo_names[i] == 'MostPopular':\n",
        "        top_n = get_top_n_mp_Surprise(testset, df_item_dist, n=10)\n",
        "        print(algo_names[i])\n",
        "    else:\n",
        "        top_n = get_top_n_Surprise(predictions, n=10)\n",
        "    \n",
        "    # calculate GAPs\n",
        "    low_count = 0\n",
        "    med_count = 0\n",
        "    high_count = 0\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        iid_list = []\n",
        "        for (iid, _) in user_ratings:\n",
        "            df_item_dist_Surprise.loc[iid, algo_names[i]] += 1\n",
        "            iid_list.append(iid)\n",
        "        gap = sum(df_item_dist_Surprise[\"count\"].loc[iid_list]) / len(iid_list)\n",
        "        if uid in low.index:\n",
        "            low_rec_gap += gap\n",
        "            low_count += 1\n",
        "        elif uid in med.index:\n",
        "            medium_rec_gap += gap\n",
        "            med_count += 1\n",
        "        elif uid in high.index:\n",
        "            high_rec_gap += gap\n",
        "            high_count += 1\n",
        "    low_rec_gap_list.append(low_rec_gap / low_count)\n",
        "    medium_rec_gap_list.append(medium_rec_gap / med_count)\n",
        "    high_rec_gap_list.append(high_rec_gap / high_count)\n",
        "    i += 1 # next algorithm\n",
        "    end = time.time()\n",
        "    print(\"It took \" + str(np.round(end-start)) + \" seconds.\")\n",
        "    start = time.time()"
      ],
      "metadata": {
        "id": "YSMxxqmhOJi_",
        "outputId": "3dd7b16e-2753-4c9a-a6f6-0c73399b8e5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~~~~~~~~~~~~~~~~NEW~~~~~~~~~~~~~~~~~\n",
            "Random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 1/7 [00:16<01:40, 16.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 17.0 seconds.\n",
            "~~~~~~~~~~~~~~~~NEW~~~~~~~~~~~~~~~~~\n",
            "MostPopular\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 2/7 [00:33<01:25, 17.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 17.0 seconds.\n",
            "~~~~~~~~~~~~~~~~NEW~~~~~~~~~~~~~~~~~\n",
            "Estimating biases using als...\n",
            "UserItemAvg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 3/7 [00:41<00:51, 12.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 8.0 seconds.\n",
            "~~~~~~~~~~~~~~~~NEW~~~~~~~~~~~~~~~~~\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "UserKNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 4/7 [00:51<00:34, 11.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 10.0 seconds.\n",
            "~~~~~~~~~~~~~~~~NEW~~~~~~~~~~~~~~~~~\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "UserKNNAvg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 5/7 [01:01<00:22, 11.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 10.0 seconds.\n",
            "~~~~~~~~~~~~~~~~NEW~~~~~~~~~~~~~~~~~\n",
            "NMF\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 6/7 [01:14<00:11, 11.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 13.0 seconds.\n",
            "~~~~~~~~~~~~~~~~NEW~~~~~~~~~~~~~~~~~\n",
            "SVD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [01:25<00:00, 12.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 11.0 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not implemented here yet.\n",
        "# if train_way == \"kfold\":\n",
        "#     for alg in algo_names:\n",
        "#         df_item_dist[alg] = df_item_dist[alg]/n_splits"
      ],
      "metadata": {
        "id": "OhV-OMlwYIxJ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_item_dist_Surprise[:100]"
      ],
      "metadata": {
        "id": "aLW_xY3dYYaN",
        "outputId": "3a089940-76e9-46ba-b1b5-f57592e1c8f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          count  Random  MostPopular  UserItemAvg  UserKNN  UserKNNAvg  NMF  \\\n",
              "421    0.055049       6         5357           65       65          65   65   \n",
              "424    0.043567       5         5357           60       60          60   59   \n",
              "1365   0.031299       6         5357           38       38          38   38   \n",
              "1464   0.029569      13         5357           44       43          44   44   \n",
              "2836   0.028311       8         5357           39       38          38   39   \n",
              "...         ...     ...          ...          ...      ...         ...  ...   \n",
              "10954  0.011167       8            0           23       23          23   23   \n",
              "1482   0.011167      12            0           17       16          16   16   \n",
              "855    0.011167       8            0           13       13          13   12   \n",
              "5600   0.011010       8            0           16       15          15   16   \n",
              "2039   0.011010       4            0            7        7           7    7   \n",
              "\n",
              "       SVD  \n",
              "421     65  \n",
              "424     60  \n",
              "1365    38  \n",
              "1464    44  \n",
              "2836    38  \n",
              "...    ...  \n",
              "10954   23  \n",
              "1482    16  \n",
              "855     13  \n",
              "5600    16  \n",
              "2039     7  \n",
              "\n",
              "[100 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11b36548-4872-4267-8b76-c77999d7df4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>Random</th>\n",
              "      <th>MostPopular</th>\n",
              "      <th>UserItemAvg</th>\n",
              "      <th>UserKNN</th>\n",
              "      <th>UserKNNAvg</th>\n",
              "      <th>NMF</th>\n",
              "      <th>SVD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>0.055049</td>\n",
              "      <td>6</td>\n",
              "      <td>5357</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>0.043567</td>\n",
              "      <td>5</td>\n",
              "      <td>5357</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>59</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1365</th>\n",
              "      <td>0.031299</td>\n",
              "      <td>6</td>\n",
              "      <td>5357</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1464</th>\n",
              "      <td>0.029569</td>\n",
              "      <td>13</td>\n",
              "      <td>5357</td>\n",
              "      <td>44</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2836</th>\n",
              "      <td>0.028311</td>\n",
              "      <td>8</td>\n",
              "      <td>5357</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10954</th>\n",
              "      <td>0.011167</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1482</th>\n",
              "      <td>0.011167</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>0.011167</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5600</th>\n",
              "      <td>0.011010</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2039</th>\n",
              "      <td>0.011010</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11b36548-4872-4267-8b76-c77999d7df4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11b36548-4872-4267-8b76-c77999d7df4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11b36548-4872-4267-8b76-c77999d7df4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save files\n",
        "To save:\n",
        "1. df_item_dist\n",
        "2. low_rec_gap_list etc"
      ],
      "metadata": {
        "id": "RNCXpu13bYo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save = True"
      ],
      "metadata": {
        "id": "p6Z7JKwXbYpB"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if save:\n",
        "  from google.colab import drive\n",
        "  import pickle as pkl\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  df_item_dist_Surprise.to_csv(\"/content/drive/My Drive/item_pop_dist\"+addition_1+\"_results_Surprise.csv\")\n",
        "  with open(\"/content/drive/My Drive/low_rec_gap_list_Surprise\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(low_rec_gap_list,f)\n",
        "  with open(\"/content/drive/My Drive/med_rec_gap_list_Surprise\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(medium_rec_gap_list,f)\n",
        "  with open(\"/content/drive/My Drive/high_rec_gap_list_Surprise\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(high_rec_gap_list,f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f54022-69be-4b60-a4f4-e1f24bee92a8",
        "id": "-pGCUO7qbYpF"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe6or3ho6USn"
      },
      "source": [
        "### Cornac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "eMpAQsgL6USo"
      },
      "outputs": [],
      "source": [
        "# load dataset in Cornac\n",
        "reader = CornacReader()\n",
        "data = reader.read(user_events_file.split(\"/\")[-1],sep =\",\", skip_lines =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "lZnmi5_l6USo"
      },
      "outputs": [],
      "source": [
        "# Split the data based on ratio\n",
        "rs = RatioSplit(data=data, test_size=test_size, rating_threshold=rating_threshold, seed=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "otDvr-GB6USp"
      },
      "outputs": [],
      "source": [
        "# initialize models, here we are comparing: simple, traditional, and neural networks based models\n",
        "models = [\n",
        "          # 1: Random\n",
        "          # 2: MostPop\n",
        "          MostPop(),\n",
        "          # 3: UserKNN\n",
        "          # 4: BPR\n",
        "          BPR(k=10, max_iter=200, learning_rate=0.001, lambda_reg=0.01, seed=123),\n",
        "          # 5: MF\n",
        "          MF(k=30, max_iter=100, learning_rate=0.01, lambda_reg=0.001, seed=123),\n",
        "          # 6: PMF\n",
        "          PMF(k=10, max_iter=100, learning_rate=0.001, lambda_reg=0.001),\n",
        "          # 7: NMF\n",
        "          NMF(k=15, max_iter=50, learning_rate=0.005, lambda_u=0.06, lambda_v=0.06, lambda_bu=0.02, lambda_bi=0.02, use_bias=False, verbose=True, seed=123),\n",
        "          # 8: WMF\n",
        "          WMF(k=50, max_iter=50, learning_rate=0.001, lambda_u=0.01, lambda_v=0.01, verbose=True, seed=123),\n",
        "          # 9: PF\n",
        "          HPF(k=50, seed=123, hierarchical=False, name=\"PF\"),\n",
        "          # 10: NueMF\n",
        "          NeuMF(num_factors=8, layers=[32, 16, 8], act_fn=\"tanh\", num_epochs=1, num_neg=3, batch_size=256, lr=0.001, seed=42, verbose=True),\n",
        "          # 11: VAECF\n",
        "          VAECF(k=10, autoencoder_structure=[20], act_fn=\"tanh\", likelihood=\"mult\", n_epochs=100, batch_size=100, learning_rate=0.001, beta=1.0, seed=123, use_gpu=True, verbose=True)\n",
        "          ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erbjctPK6USq"
      },
      "outputs": [],
      "source": [
        "# define metrics to evaluate the models\n",
        "metrics = [MAE(), MSE(), RMSE(), AUC(), MAP(), MRR(), \n",
        "           Precision(k=5), Precision(k=10), Precision(k=20), Precision(k=50),\n",
        "           Recall(k=5), Recall(k=10), Recall(k=20), Recall(k=50),\n",
        "           NDCG(k=5), NDCG(k=10), NDCG(k=20), NDCG(k=50),\n",
        "           FMeasure(k=5), FMeasure(k=10), FMeasure(k=20), FMeasure(k=50)]\n",
        "\n",
        "# put it together in an experiment, voilà!\n",
        "exp = cornac.Experiment(eval_method=rs, models=models, metrics=metrics, user_based=True)\n",
        "exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_user_knn(C):\n",
        "  ctime = time.time()\n",
        "  print(\"Training User-based Collaborative Filtering...\", )\n",
        "\n",
        "  sim = C.dot(C.T)\n",
        "  norms = [norm(C[i]) for i in range(C.shape[0])]\n",
        "\n",
        "  for i in tqdm(range(C.shape[0])):\n",
        "    sim[i][i] = 0.0\n",
        "    for j in range(i+1, C.shape[0]):\n",
        "      sim[i][j] /= (norms[i] * norms[j])\n",
        "      sim[j][i] /= (norms[i] * norms[j])\n",
        "\n",
        "  print(\"Done. Elapsed time:\", time.time() - ctime, \"s\")\n",
        "  rec_score = sim.dot(C)\n",
        "  return rec_score"
      ],
      "metadata": {
        "id": "UnhS3ZT87sXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_training_data():\n",
        "  training_matrix = np.zeros((rs.train_set.matrix.shape[0], rs.train_set.matrix.shape[1]))\n",
        "  for uid in tqdm(rs.train_set.uid_map.values()):\n",
        "    for iid in rs.train_set.iid_map.values():\n",
        "      training_matrix[uid, iid] = rs.train_set.matrix[uid, iid]\n",
        "  return training_matrix"
      ],
      "metadata": {
        "id": "Hr55g2GF7xSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating users-books rating matrix (will be used for User-KNN algorithm)\n",
        "training_matrix = read_training_data()"
      ],
      "metadata": {
        "id": "V7IpeOlm70dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# running User-KNN algorithms and getting the user-book scores\n",
        "user_knn_scores = compute_user_knn(training_matrix)"
      ],
      "metadata": {
        "id": "XzkJFwrJ72Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UserKNN recommendation algorithm\n",
        "def get_top_n_UserKNN(n=10):\n",
        "    print(\"User-KNN model is selected:\")\n",
        "    top_n = defaultdict(list)\n",
        "    # test_items = list(rs.test_set.iid_map.keys())\n",
        "    for uid in rs.train_set.uid_map.values():\n",
        "      user_id = list(rs.train_set.user_ids)[uid]\n",
        "      top_n_items_idxs = list(reversed(user_knn_scores[uid].argsort()))[:n]\n",
        "      for iid in top_n_items_idxs:\n",
        "        item_id = list(rs.train_set.item_ids)[iid]\n",
        "        top_n[int(user_id)].append((int(item_id), user_knn_scores[uid][iid]))\n",
        "    return top_n"
      ],
      "metadata": {
        "id": "8R-5uOIt74me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n(algo_name, n=10):\n",
        "  for model in exp.models:\n",
        "    if model.name == algo_name:\n",
        "      print(model.name + \" model is selected:\")\n",
        "      top_n = defaultdict(list)\n",
        "      for uid in model.train_set.uid_map.values():\n",
        "        user_id = list(model.train_set.user_ids)[uid]\n",
        "        try:\n",
        "          item_rank = model.rank(user_idx=uid)[0]\n",
        "        except:\n",
        "          item_rank = model.rank(user_idx=int(uid))[0]\n",
        "        # collect top N items\n",
        "        item_rank_top = item_rank[:n]\n",
        "        for iid in item_rank_top:\n",
        "          item_id = list(model.train_set.item_ids)[iid]\n",
        "          top_n[int(user_id)].append((int(item_id), model.score(uid, iid)))\n",
        "  return top_n"
      ],
      "metadata": {
        "id": "awd4TmF476qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random recommendation algorithm\n",
        "def get_top_n_random(n=10):\n",
        "    print(\"Random model is selected:\")\n",
        "    top_n = defaultdict(list)\n",
        "    test_items = list(rs.test_set.iid_map.keys())\n",
        "    for uid in rs.train_set.uid_map.values():\n",
        "      if uid not in top_n.keys():\n",
        "        user_id = list(rs.train_set.user_ids)[uid]\n",
        "        for i in range(0, n):\n",
        "          top_n[int(user_id)].append((int(rd.choice(test_items)), i))\n",
        "    return top_n"
      ],
      "metadata": {
        "id": "zmssLS8z7883"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo_names = ['Random', 'MostPop', 'UserKNN', 'MF', 'PMF', 'BPR', 'NMF', 'WMF', 'PF', 'NeuMF', 'VAECF']\n",
        "\n",
        "i = 0\n",
        "low_rec_gap_list = [] # one entry per algorithmus\n",
        "medium_rec_gap_list = []\n",
        "high_rec_gap_list = []\n",
        "\n",
        "for i in range(0, len(algo_names)):\n",
        "    df_item_dist[algo_names[i]] = 0\n",
        "    low_rec_gap = 0\n",
        "    medium_rec_gap = 0\n",
        "    high_rec_gap = 0\n",
        "    \n",
        "    if algo_names[i] == 'Random':\n",
        "      top_n = get_top_n_random(n=10)\n",
        "    elif algo_names[i] == 'UserKNN':\n",
        "      top_n = get_top_n_UserKNN(n=10)\n",
        "    else:\n",
        "      top_n = get_top_n(algo_names[i], n=10)\n",
        "    low_count = 0\n",
        "    med_count = 0\n",
        "    high_count = 0\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        iid_list = []\n",
        "        for (iid, _) in user_ratings:\n",
        "            df_item_dist.loc[iid, algo_names[i]] += 1\n",
        "            iid_list.append(iid)\n",
        "        gap = sum(df_item_dist[\"count\"].loc[iid_list]) / len(iid_list)\n",
        "        if uid in low.index:\n",
        "            low_rec_gap += gap\n",
        "            low_count += 1\n",
        "        elif uid in med.index:\n",
        "            medium_rec_gap += gap\n",
        "            med_count += 1\n",
        "        elif uid in high.index:\n",
        "            high_rec_gap += gap\n",
        "            high_count += 1\n",
        "    low_rec_gap_list.append(low_rec_gap / low_count)\n",
        "    medium_rec_gap_list.append(medium_rec_gap / med_count)\n",
        "    high_rec_gap_list.append(high_rec_gap / high_count)\n",
        "    i += 1 # next algorithm"
      ],
      "metadata": {
        "id": "x3a0gJqr7-4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save files\n",
        "To save:\n",
        "1. df_item_dist\n",
        "2. low_rec_gap_list etc\n",
        "3. exp.result & exp.metric\n",
        "4. training user ids"
      ],
      "metadata": {
        "id": "Buq5Z1f45DhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save = True"
      ],
      "metadata": {
        "id": "4jM6jAdTlwUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if save:\n",
        "  from google.colab import drive\n",
        "  import pickle as pkl\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  df_item_dist.to_csv(\"/content/drive/My Drive/item_pop_dist\"+addition_1+\"_results_Cornac.csv\")\n",
        "  with open(\"/content/drive/My Drive/experiment_results_cornac\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(exp.result,f)\n",
        "  with open(\"/content/drive/My Drive/experiment_metrics_cornac\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(exp.metrics,f)\n",
        "  with open(\"/content/drive/My Drive/low_rec_gap_list_cornac\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(low_rec_gap_list,f)\n",
        "  with open(\"/content/drive/My Drive/med_rec_gap_list_cornac\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(medium_rec_gap_list,f)\n",
        "  with open(\"/content/drive/My Drive/high_rec_gap_list_cornac\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(high_rec_gap_list,f)\n",
        "  with open(\"/content/drive/My Drive/training_user_ids\"+addition_4+\"_cornac.pkl\",\"wb\") as f:\n",
        "    pkl.dump(list(rs.train_set.user_ids),f)"
      ],
      "metadata": {
        "id": "HTXH7c-r6G5v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Book recommendation.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}