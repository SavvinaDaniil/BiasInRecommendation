{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdmWUJCl6USJ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SavvinaDaniil/BiasInRecommendation/blob/main/2.%20Book%20Recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZEwzP5d6USR"
      },
      "source": [
        "This notebook should be run on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCeSb4Vu6USS"
      },
      "source": [
        "# Process\n",
        "In this notebook, I will train the book recommendation algorithms using two different packages: <a href=\"http://surpriselib.com/\">Surprise</a> & <a href=\"https://cornac.readthedocs.io/en/latest/\">Cornac</a>. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7QlcgcE6USU"
      },
      "source": [
        "## A. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPmwTeS66USV",
        "outputId": "115d965a-570e-4491-bb01-42fb6331ccda",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cornac\n",
            "  Downloading cornac-1.14.2-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 4.4 MB/s \n",
            "\u001b[?25hCollecting powerlaw\n",
            "  Downloading powerlaw-1.5-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from cornac) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cornac) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cornac) (1.7.3)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from powerlaw->cornac) (1.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from powerlaw->cornac) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->powerlaw->cornac) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->powerlaw->cornac) (1.15.0)\n",
            "Installing collected packages: powerlaw, cornac\n",
            "Successfully installed cornac-1.14.2 powerlaw-1.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.7.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1633726 sha256=ad0ef510617cd1d3253068901dcf1cb7533697eb37eed1d2f3ff844703dd4683\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install cornac\n",
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47V5DR7s6USa",
        "outputId": "c197882d-20bd-4b89-fa8a-bcab337402b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Tensorflow 1 is deprecated, and support will be removed on August 1, 2022.\n",
            "After that, `%tensorflow_version 1.x` will throw an error.\n",
            "\n",
            "Your notebook should be updated to use Tensorflow 2.\n",
            "See the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2.\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#from run_algorithms import train_algorithms, train_algorithms_kf, prepare_dataset, prepare_dataset_kf\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "pd.set_option(\"display.precision\", 6)\n",
        "\n",
        "# Cornac imports\n",
        "import cornac\n",
        "from cornac.eval_methods import RatioSplit\n",
        "from cornac.data import Reader as CornacReader #Reader exists in both packages\n",
        "from cornac.models import MostPop, MF, PMF, BPR, NeuMF, WMF, HPF, VAECF, NMF\n",
        "from cornac.models import NMF as CornacNMF #NMF exists in both packages\n",
        "from cornac.metrics import MAE, MSE, RMSE, Precision, Recall, NDCG, AUC, MAP, FMeasure, MRR\n",
        "\n",
        "from surprise import BaselineOnly, KNNBasic, KNNWithMeans, SVDpp, SVD\n",
        "from surprise import NMF as SurpriseNMF #NMF exists in both packages\n",
        "from surprise import Dataset\n",
        "from surprise import Reader as SurpriseReader #Reader exists in both packages\n",
        "from surprise.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from surprise import accuracy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from collections import defaultdict\n",
        "from scipy import stats\n",
        "from numpy.linalg import norm\n",
        "import seaborn as sns\n",
        "# set plot style: grey grid in the background:\n",
        "sns.set(style=\"darkgrid\")\n",
        "pd.set_option(\"display.precision\", 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxc749MS6USc"
      },
      "source": [
        "## B. Set hyperparameters\n",
        "There are certain hyperparameters that need to be tuned before the run. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KpDdroKt6USd"
      },
      "outputs": [],
      "source": [
        "item_threshold = 5 # remove users with less than item_threshold items\n",
        "user_threshold = 5 # remove items with less than user_threshold users\n",
        "top_threshold = 200 # remove users who have rated more than top_threshold items\n",
        "recommendation_type = \"books\" # books, music or movies\n",
        "item_col = \"book\" # the item column\n",
        "my_seed = 0 # random_seed\n",
        "top_fraction_items = 0.2 # the limit for an item to be considered popular\n",
        "top_fraction_users = 0.2# the limit for a user to be considered High Mainstriminess\n",
        "split_by = \"pop_fraq\" # sort users by fraction of popular items (pop_fraq) or by average popularity in profile (pop_item_fraq)\n",
        "test_size = 0.2 # the percentage of \"hold out\" data that are used for testing\n",
        "rating_threshold = 1.0 # needed for the cornac library\n",
        "predict_col = \"rating\" # the column we are predicting\n",
        "train_way = \"simple_split\"\n",
        "n_splits = 5 # the amount of splits\n",
        "\n",
        "if train_way == \"simple_split\": n_splits = 1\n",
        "rd.seed(my_seed)\n",
        "np.random.seed(my_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSnYGMbb6USg"
      },
      "source": [
        "These additions will be useful so we can load and save the different files (plots and processed data) with clarity on the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oYgsM9m86USh"
      },
      "outputs": [],
      "source": [
        "addition_1 = \"_u\"+str(item_threshold)+\"_i\"+str(user_threshold)+\"_t\"+str(top_threshold)\n",
        "addition_2 = addition_1 + \"_tfi\"+str(int(100*top_fraction_items))\n",
        "addition_3 = addition_2 + \"_tfu\"+str(int(100*top_fraction_users))\n",
        "addition_4 = addition_3 + (\"_sbpf\" if (split_by==\"pop_fraq\") else \"_sbpif\")\n",
        "addition_gender = addition_2 + \"_mfd\"\n",
        "addition_country = addition_2 + \"_USAr\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbqK-CH56USj"
      },
      "source": [
        "## C. Read files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heXv-FIr6GIR"
      },
      "source": [
        "General."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "utMWqIUK6USk"
      },
      "outputs": [],
      "source": [
        "user_events_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/ratings\"+addition_1+\"_new.csv\"\n",
        "high_user_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/high_users\"+addition_4+\"_new.csv\"\n",
        "low_user_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/low_users\"+addition_4+\"_new.csv\"\n",
        "medium_user_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/med_users\"+addition_4+\"_new.csv\"\n",
        "df_item_dist_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/item_pop_dist\"+addition_1+\"_new.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzjlmbMS6H50"
      },
      "source": [
        "Gender."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_vg8t_FMIVgV"
      },
      "outputs": [],
      "source": [
        "male_oriented_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/books/high_users_u5_i5_t200_tfu20_mfd_new.csv\"\n",
        "diverse_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/books/med_users_u5_i5_t200_tfu20_mfd_new.csv\"\n",
        "female_oriented_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/books/low_users_u5_i5_t200_tfu20_mfd_new.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An_b9dDJ6eRY"
      },
      "source": [
        "Country."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fKd2M9K9u5G6"
      },
      "outputs": [],
      "source": [
        "USA_oriented_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/books/high_users_u5_i5_t200_tfu20_USAr_new.csv\"\n",
        "midUSA_oriented_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/books/med_users_u5_i5_t200_tfu20_USAr_new.csv\"\n",
        "lowUSA_oriented_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/books/low_users_u5_i5_t200_tfu20_USAr_new.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STNpdNmp6fkL"
      },
      "source": [
        "Read all files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WsWUflDo8K25"
      },
      "outputs": [],
      "source": [
        "low_popularity = pd.read_csv(low_user_file, index_col=0)\n",
        "med_popularity = pd.read_csv(medium_user_file, index_col=0)\n",
        "high_popularity = pd.read_csv(high_user_file, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AIfIozpLI0KW"
      },
      "outputs": [],
      "source": [
        "male_oriented = pd.read_csv(male_oriented_file, index_col=0)\n",
        "diverse = pd.read_csv(diverse_file, index_col=0)\n",
        "female_oriented = pd.read_csv(female_oriented_file, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3yQOz5sgvDZh"
      },
      "outputs": [],
      "source": [
        "USA_oriented = pd.read_csv(USA_oriented_file, index_col=0)\n",
        "midUSA_oriented = pd.read_csv(midUSA_oriented_file, index_col=0)\n",
        "lowUSA_oriented = pd.read_csv(lowUSA_oriented_file, index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fp90eoS6mfL"
      },
      "source": [
        "Confirm number of users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTH6eEdX4sw8",
        "outputId": "2f2c00f9-48c5-48a0-86b4-3c531842def7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6354 6354 6354\n"
          ]
        }
      ],
      "source": [
        "num_users1 = len(low_popularity) + len(med_popularity) + len(high_popularity)\n",
        "num_users2 = len(male_oriented) + len(diverse) + len(female_oriented)\n",
        "num_users3 = len(USA_oriented) + len(midUSA_oriented) + len(lowUSA_oriented)\n",
        "print(num_users1, num_users2, num_users3)\n",
        "num_users = num_users1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL868j5U6vbl"
      },
      "source": [
        "Distribution of items (for popularity)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pUKKcoUG81fK"
      },
      "outputs": [],
      "source": [
        "df_item_dist = pd.read_csv(df_item_dist_file, index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wVLsu75bjGga",
        "outputId": "c0cb012e-b88a-4054-86c2-92bda707b18b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          count\n",
              "121  0.05901794\n",
              "68   0.04359459\n",
              "40   0.03981744\n",
              "413  0.03903053\n",
              "443  0.03729934"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0408643-494d-44d5-a856-1327a094da0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>0.05901794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>0.04359459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.03981744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>0.03903053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>0.03729934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0408643-494d-44d5-a856-1327a094da0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0408643-494d-44d5-a856-1327a094da0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0408643-494d-44d5-a856-1327a094da0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df_item_dist.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH7BETV86USm"
      },
      "source": [
        "## D. Recommendation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Rm5kOIQMOUa2"
      },
      "outputs": [],
      "source": [
        "# we need two df_item_dist: one for Surprise, one for Cornac\n",
        "df_item_dist_Surprise = df_item_dist.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ctrkzpEGyb0"
      },
      "source": [
        "### Surprise\n",
        "Skip for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGMFHd54JUOh"
      },
      "outputs": [],
      "source": [
        "# df_events = pd.read_csv(user_events_file, low_memory = False, header=0) # create dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmZPcpzaG4dH"
      },
      "outputs": [],
      "source": [
        "# # load dataset in Surprise\n",
        "# reader = SurpriseReader(rating_scale=(df_events[predict_col].min(), df_events[predict_col].max()))\n",
        "# data = Dataset.load_from_df(df_events, reader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxOL9xlVJ27r"
      },
      "outputs": [],
      "source": [
        "# # split in train and test set\n",
        "# trainset, testset = train_test_split(data, test_size = test_size, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6M3o5Z8KMlO"
      },
      "outputs": [],
      "source": [
        "# # select and initialize algorithms\n",
        "# algo_names = [\"Random\",\n",
        "#               \"MostPopular\",\n",
        "#               #'UserItemAvg',\n",
        "#                   'UserKNN',\n",
        "#                   'UserKNNAvg',\n",
        "#                   'NMF', \n",
        "#                   'SVD']\n",
        "\n",
        "# # the default parameters for all algorithms\n",
        "# algos = [] \n",
        "# algos.append(None)#Random())\n",
        "# algos.append(None)#MostPopular())\n",
        "# #algos.append(BaselineOnly()) \n",
        "# algos.append(KNNBasic(sim_options = {'name': 'cosine', 'user_based': True})) \n",
        "# algos.append(KNNWithMeans(sim_options = {'name': 'cosine', 'user_based': True})) \n",
        "# algos.append(SurpriseNMF())\n",
        "# algos.append(SVD())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1t4g_mvPcXB"
      },
      "outputs": [],
      "source": [
        "# def get_top_n_Surprise(predictions, n=10):\n",
        "#     # First map the predictions to each user.\n",
        "#     top_n = defaultdict(list)\n",
        "#     for uid, iid, true_r, est, _ in predictions:\n",
        "#         top_n[uid].append((iid, est))\n",
        "#     # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "#     for uid, user_ratings in top_n.items():\n",
        "#         user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "#         top_n[uid] = user_ratings[:n]\n",
        "#     return top_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EsIyRzKPrGD"
      },
      "outputs": [],
      "source": [
        "# def get_top_n_random_Surprise(testset, df_item_dist, n=10):\n",
        "#     top_n = defaultdict(list)\n",
        "#     for uid, iid, true_r in testset:\n",
        "#       if len(top_n[uid]) == 0:\n",
        "#         for i in range(0, 10):\n",
        "#           top_n[uid].append((rd.choice(df_item_dist.index), i))\n",
        "    \n",
        "#     return top_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMJz96S5Pvja"
      },
      "outputs": [],
      "source": [
        "# def get_top_n_mp_Surprise(testset, item_dist, n=10):\n",
        "#     top_n = defaultdict(list)\n",
        "#     for uid, iid, true_r in testset:\n",
        "#         if len(top_n[uid]) == 0:\n",
        "#             for iid, count in df_item_dist[:n][\"count\"].items():\n",
        "#                 top_n[uid].append((iid, count))\n",
        "#     return top_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2Y5C_k2g810"
      },
      "outputs": [],
      "source": [
        "# trainset_for_testing = trainset.build_anti_testset() + trainset.build_testset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rSoQVlMASti"
      },
      "outputs": [],
      "source": [
        "# len(trainset_for_testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WARtuWfAU92"
      },
      "outputs": [],
      "source": [
        "# trainset2 = trainset.build_anti_testset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSMxxqmhOJi_"
      },
      "outputs": [],
      "source": [
        "# i = 0\n",
        "# low_rec_gap_list = [] # one entry per algorithm\n",
        "# medium_rec_gap_list = []\n",
        "# high_rec_gap_list = []\n",
        "# start = time.time()\n",
        "\n",
        "# for i in tqdm(range(0, len(algo_names))): # for every algorithm\n",
        "#     print(\"~~~~~~~~~~~~~~~~NEW~~~~~~~~~~~~~~~~~\")\n",
        "#     df_item_dist_Surprise[algo_names[i]] = 0 # I am adding a column to Surprise\n",
        "#     low_rec_gap = 0\n",
        "#     medium_rec_gap = 0\n",
        "#     high_rec_gap = 0\n",
        "    \n",
        "#     # get accuracy for personalized approaches\n",
        "#     if algo_names[i] != 'Random' and algo_names[i] != 'MostPopular': # for proper algorithms\n",
        "#         algos[i].fit(trainset) # fit\n",
        "#         predictions = algos[i].test(trainset2) # predict\n",
        "#         print(algo_names[i]) # end of fitting\n",
        "\n",
        "#         #get_mae_of_groups(predictions, low, med, high) TO BE ADDED\n",
        "    \n",
        "#     # get top-n items and calculate gaps for all algorithms\n",
        "#     if algo_names[i] == 'Random':\n",
        "#         top_n = get_top_n_random_Surprise(trainset2, df_item_dist, n=10)\n",
        "#         print(algo_names[i])\n",
        "#     elif algo_names[i] == 'MostPopular':\n",
        "#         top_n = get_top_n_mp_Surprise(trainset2, df_item_dist, n=10)\n",
        "#         print(algo_names[i])\n",
        "#     else:\n",
        "#         top_n = get_top_n_Surprise(predictions, n=10)\n",
        "\n",
        "#     # calculate GAPs\n",
        "#     low_count = 0\n",
        "#     med_count = 0\n",
        "#     high_count = 0\n",
        "#     for uid, user_ratings in top_n.items():\n",
        "#         iid_list = []\n",
        "#         for (iid, _) in user_ratings:\n",
        "#             df_item_dist_Surprise.loc[iid, algo_names[i]] += 1\n",
        "#             iid_list.append(iid)\n",
        "#         gap = sum(df_item_dist_Surprise[\"count\"].loc[iid_list]) / len(iid_list)\n",
        "#         if uid in low.index:\n",
        "#             low_rec_gap += gap\n",
        "#             low_count += 1\n",
        "#         elif uid in med.index:\n",
        "#             medium_rec_gap += gap\n",
        "#             med_count += 1\n",
        "#         elif uid in high.index:\n",
        "#             high_rec_gap += gap\n",
        "#             high_count += 1\n",
        "#     low_rec_gap_list.append(low_rec_gap / low_count)\n",
        "#     medium_rec_gap_list.append(medium_rec_gap / med_count)\n",
        "#     high_rec_gap_list.append(high_rec_gap / high_count)\n",
        "#     i += 1 # next algorithm\n",
        "#     end = time.time()\n",
        "#     print(\"It took \" + str(np.round(end-start)) + \" seconds.\")\n",
        "#     start = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhV-OMlwYIxJ"
      },
      "outputs": [],
      "source": [
        "# Not implemented here yet.\n",
        "# if train_way == \"kfold\":\n",
        "#     for alg in algo_names:\n",
        "#         df_item_dist[alg] = df_item_dist[alg]/n_splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLW_xY3dYYaN"
      },
      "outputs": [],
      "source": [
        "# #len(np.unique([x[0] for x in trainset_for_testing])),\n",
        "# len(np.unique([x[0] for x in testset]))  # unique users\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5ICEtVTikmG"
      },
      "outputs": [],
      "source": [
        "# #len(np.unique([x[1] for x in trainset_for_testing])),\n",
        "# len(np.unique([x[1] for x in testset])) # unique items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNCXpu13bYo1"
      },
      "source": [
        "#### Save files\n",
        "Skip for now.\n",
        "\n",
        "To save:\n",
        "1. df_item_dist\n",
        "2. low_rec_gap_list etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6Z7JKwXbYpB"
      },
      "outputs": [],
      "source": [
        "# save = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pGCUO7qbYpF"
      },
      "outputs": [],
      "source": [
        "# if save:\n",
        "#   from google.colab import drive\n",
        "#   import pickle as pkl\n",
        "#   drive.mount('/content/drive')\n",
        "\n",
        "#   df_item_dist_Surprise.to_csv(\"/content/drive/My Drive/item_pop_dist\"+addition_1+\"_results_Surprise.csv\")\n",
        "#   with open(\"/content/drive/My Drive/low_rec_gap_list_Surprise\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "#     pkl.dump(low_rec_gap_list,f)\n",
        "#   with open(\"/content/drive/My Drive/med_rec_gap_list_Surprise\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "#     pkl.dump(medium_rec_gap_list,f)\n",
        "#   with open(\"/content/drive/My Drive/high_rec_gap_list_Surprise\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "#     pkl.dump(high_rec_gap_list,f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe6or3ho6USn"
      },
      "source": [
        "### Cornac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eMpAQsgL6USo"
      },
      "outputs": [],
      "source": [
        "# load dataset in Cornac\n",
        "os.system(\"wget \"+user_events_file)\n",
        "reader = CornacReader()\n",
        "data = reader.read(user_events_file.split(\"/\")[-1],sep =\",\", skip_lines =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lZnmi5_l6USo"
      },
      "outputs": [],
      "source": [
        "# Split the data based on ratio\n",
        "rs = RatioSplit(data=data, test_size=test_size, rating_threshold=rating_threshold, seed=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "otDvr-GB6USp"
      },
      "outputs": [],
      "source": [
        "# initialize models, here we are comparing: simple, traditional, and neural networks based models\n",
        "models = [\n",
        "          # 1: Random\n",
        "          # 2: MostPop\n",
        "          MostPop(),\n",
        "          # 3: UserKNN\n",
        "          # 4: BPR\n",
        "          BPR(k=10, max_iter=200, learning_rate=0.001, lambda_reg=0.01, seed=123),\n",
        "          # 5: MF\n",
        "          MF(k=30, max_iter=100, learning_rate=0.01, lambda_reg=0.001, seed=123),\n",
        "          # 6: PMF\n",
        "          PMF(k=10, max_iter=100, learning_rate=0.001, lambda_reg=0.001),\n",
        "          # 7: NMF\n",
        "          NMF(k=15, max_iter=50, learning_rate=0.005, lambda_u=0.06, lambda_v=0.06, lambda_bu=0.02, lambda_bi=0.02, use_bias=False, verbose=True, seed=123),\n",
        "          # 8: WMF\n",
        "          WMF(k=50, max_iter=50, learning_rate=0.001, lambda_u=0.01, lambda_v=0.01, verbose=True, seed=123),\n",
        "          # 9: PF\n",
        "          HPF(k=50, seed=123, hierarchical=False, name=\"PF\"),\n",
        "          # 10: NueMF\n",
        "          NeuMF(num_factors=8, layers=[32, 16, 8], act_fn=\"tanh\", num_epochs=1, num_neg=3, batch_size=256, lr=0.001, seed=42, verbose=True),\n",
        "          # 11: VAECF\n",
        "          VAECF(k=10, autoencoder_structure=[20], act_fn=\"tanh\", likelihood=\"mult\", n_epochs=100, batch_size=100, learning_rate=0.001, beta=1.0, seed=123, use_gpu=True, verbose=True)\n",
        "          ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "7f80115633d848e2a2a121f0326b55aa",
            "bfad63423adb40529004a9c3aacbe990",
            "dec6e19cefb74441a093c95f35900108",
            "dc06fabee4394b7aad3f312345a05bff",
            "0bae2ea1bf1743e892183934a617c1a3",
            "f4b19eabe09141be965801546342ada7",
            "96dc358917fb416e8dc25cb90959ec17",
            "a808c7adc0c4422d9b80971bbd2c63d1",
            "dce9af9fe4b14fa59e2c9072aba57ba1",
            "c820e981895c4e5c9482a6c2bbd5f2de",
            "0928dacf69c24a31a0b138272eaaa36b"
          ]
        },
        "id": "erbjctPK6USq",
        "outputId": "1f24438f-08dd-440d-a32e-b8d59d4c5d8c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f80115633d848e2a2a121f0326b55aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization finished!\n"
          ]
        }
      ],
      "source": [
        "# define metrics to evaluate the models\n",
        "metrics = [MAE(), MSE(), RMSE(), AUC(), MAP(), MRR(), \n",
        "           Precision(k=5), Precision(k=10), Precision(k=20), Precision(k=50),\n",
        "           Recall(k=5), Recall(k=10), Recall(k=20), Recall(k=50),\n",
        "           NDCG(k=5), NDCG(k=10), NDCG(k=20), NDCG(k=50),\n",
        "           FMeasure(k=5), FMeasure(k=10), FMeasure(k=20), FMeasure(k=50)]\n",
        "\n",
        "# put it together in an experiment, voilà!\n",
        "exp = cornac.Experiment(eval_method=rs, models=models, metrics=metrics, user_based=True)\n",
        "exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnhS3ZT87sXb"
      },
      "outputs": [],
      "source": [
        "def compute_user_knn(C):\n",
        "  ctime = time.time()\n",
        "  print(\"Training User-based Collaborative Filtering...\", )\n",
        "\n",
        "  sim = C.dot(C.T)\n",
        "  norms = [norm(C[i]) for i in range(C.shape[0])]\n",
        "\n",
        "  for i in tqdm(range(C.shape[0])):\n",
        "    sim[i][i] = 0.0\n",
        "    for j in range(i+1, C.shape[0]):\n",
        "      sim[i][j] /= (norms[i] * norms[j])\n",
        "      sim[j][i] /= (norms[i] * norms[j])\n",
        "\n",
        "  print(\"Done. Elapsed time:\", time.time() - ctime, \"s\")\n",
        "  rec_score = sim.dot(C)\n",
        "  return rec_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr55g2GF7xSl"
      },
      "outputs": [],
      "source": [
        "def read_training_data():\n",
        "  training_matrix = np.zeros((rs.train_set.matrix.shape[0], rs.train_set.matrix.shape[1]))\n",
        "  for uid in tqdm(rs.train_set.uid_map.values()):\n",
        "    for iid in rs.train_set.iid_map.values():\n",
        "      training_matrix[uid, iid] = rs.train_set.matrix[uid, iid]\n",
        "  return training_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7IpeOlm70dg"
      },
      "outputs": [],
      "source": [
        "# creating users-books rating matrix (will be used for User-KNN algorithm)\n",
        "training_matrix = read_training_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw84cfLa2KiH"
      },
      "outputs": [],
      "source": [
        "len(training_matrix), len(training_matrix[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzkJFwrJ72Sy"
      },
      "outputs": [],
      "source": [
        "# running User-KNN algorithms and getting the user-book scores\n",
        "user_knn_scores = compute_user_knn(training_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R-5uOIt74me"
      },
      "outputs": [],
      "source": [
        "# UserKNN recommendation algorithm\n",
        "def get_top_n_UserKNN(n=100):\n",
        "    print(\"User-KNN model is selected:\")\n",
        "    top_n = defaultdict(list)\n",
        "    # test_items = list(rs.test_set.iid_map.keys())\n",
        "    for uid in rs.train_set.uid_map.values():\n",
        "      user_id = list(rs.train_set.user_ids)[uid]\n",
        "      top_n_items_idxs = list(reversed(user_knn_scores[uid].argsort()))[:n]\n",
        "      for iid in top_n_items_idxs:\n",
        "        item_id = list(rs.train_set.item_ids)[iid]\n",
        "        top_n[int(user_id)].append((int(item_id), user_knn_scores[uid][iid]))\n",
        "    return top_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awd4TmF476qI"
      },
      "outputs": [],
      "source": [
        "def get_top_n(algo_name, n=100):\n",
        "  for model in exp.models:\n",
        "    if model.name == algo_name:\n",
        "      print(model.name + \" model is selected:\")\n",
        "      top_n = defaultdict(list)\n",
        "      for uid in model.train_set.uid_map.values():\n",
        "        user_id = list(model.train_set.user_ids)[uid]\n",
        "        try:\n",
        "          item_rank = model.rank(user_idx=uid)[0] # model.rank: item rank, item_score\n",
        "        except:\n",
        "          item_rank = model.rank(user_idx=int(uid))[0]\n",
        "        # collect top N items\n",
        "        item_rank_top = item_rank[:n]\n",
        "        for iid in item_rank_top:\n",
        "          item_id = list(model.train_set.item_ids)[iid]\n",
        "          top_n[int(user_id)].append((int(item_id), model.score(uid, iid)))\n",
        "  return top_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmssLS8z7883"
      },
      "outputs": [],
      "source": [
        "# random recommendation algorithm\n",
        "def get_top_n_random(n=100):\n",
        "    print(\"Random model is selected:\")\n",
        "    top_n = defaultdict(list)\n",
        "    test_items = list(rs.test_set.iid_map.keys())\n",
        "    for uid in rs.train_set.uid_map.values():\n",
        "      if uid not in top_n.keys():\n",
        "        user_id = list(rs.train_set.user_ids)[uid]\n",
        "        for i in range(0, n):\n",
        "          top_n[int(user_id)].append((int(rd.choice(test_items)), i))\n",
        "    return top_n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oylWDP99cUYL"
      },
      "source": [
        "# Properties analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_iCRmlAe5sj"
      },
      "outputs": [],
      "source": [
        "mapped_ratings_with_properties = pd.read_csv(\"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/books/mapped_ratings_with_properties_new.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvyQz4zRBr90"
      },
      "source": [
        "Create property dictionaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e261V4U3BqX_"
      },
      "outputs": [],
      "source": [
        "gender_dict = {}\n",
        "country_dict = {}\n",
        "for isbn in mapped_ratings_with_properties.ISBN.unique():\n",
        "  gender_dict[isbn] = mapped_ratings_with_properties.gender[mapped_ratings_with_properties.ISBN == isbn].iloc[0]\n",
        "  country_dict[isbn] = mapped_ratings_with_properties.country[mapped_ratings_with_properties.ISBN == isbn].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdzRqPubhOoa",
        "outputId": "2de14a8a-448f-480f-9512-816deac6f872"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6921, 6921)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "len(gender_dict.keys()), len(country_dict.keys()) #confirm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBSQc3DlCNsw"
      },
      "source": [
        "Create columns of the relevant metric in the recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXt5eyD-q5kR"
      },
      "outputs": [],
      "source": [
        "algo_names = ['Random', 'MostPop', 'UserKNN', 'MF', 'PMF', 'BPR', 'NMF', 'WMF', 'PF', 'NeuMF', 'VAECF']\n",
        "\n",
        "for i in range(0, len(algo_names)):\n",
        "  male_oriented[\"new_male_female_difference_\"+algo_names[i]] = 0.0\n",
        "  female_oriented[\"new_male_female_difference_\"+algo_names[i]] = 0.0\n",
        "  diverse[\"new_male_female_difference_\"+algo_names[i]] = 0.0\n",
        "\n",
        "  USA_oriented[\"new_ratio_USA_\"+algo_names[i]] = 0.0\n",
        "  midUSA_oriented[\"new_ratio_USA_\"+algo_names[i]] = 0.0\n",
        "  lowUSA_oriented[\"new_ratio_USA_\"+algo_names[i]] = 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoK-7Nf_C7Ho"
      },
      "source": [
        "For every algorithm, calculated the metric (male-female difference and USA ratio) in the recommendations for every user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ1uLRRfcWHd",
        "outputId": "e9b28fde-3145-480e-f65a-49e2538df672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random model is selected:\n",
            "Top n calculated for  Random\n",
            "MostPop model is selected:\n",
            "Top n calculated for  MostPop\n",
            "User-KNN model is selected:\n",
            "Top n calculated for  UserKNN\n",
            "MF model is selected:\n",
            "Top n calculated for  MF\n",
            "PMF model is selected:\n",
            "Top n calculated for  PMF\n",
            "BPR model is selected:\n",
            "Top n calculated for  BPR\n",
            "NMF model is selected:\n",
            "Top n calculated for  NMF\n",
            "WMF model is selected:\n",
            "Top n calculated for  WMF\n",
            "PF model is selected:\n",
            "Top n calculated for  PF\n",
            "NeuMF model is selected:\n",
            "Top n calculated for  NeuMF\n",
            "VAECF model is selected:\n",
            "Top n calculated for  VAECF\n"
          ]
        }
      ],
      "source": [
        "for i in range(0, len(algo_names)):\n",
        "    male_or_diff = 0\n",
        "    diverse_diff = 0\n",
        "    female_or_diff = 0\n",
        "\n",
        "    USA_or_ratio = 0\n",
        "    midUSA_or_ratio = 0\n",
        "    lowUSA_or_ratio = 0\n",
        "    \n",
        "    if algo_names[i] == 'Random':\n",
        "      top_n = get_top_n_random(n=100)\n",
        "    elif algo_names[i] == 'UserKNN':\n",
        "      top_n = get_top_n_UserKNN(n=100)\n",
        "    else:\n",
        "      top_n = get_top_n(algo_names[i], n=100)\n",
        "    print(\"Top n calculated for \", algo_names[i])\n",
        "    users = top_n.keys()\n",
        "    user_recommendations = {}\n",
        "\n",
        "    for user in users:\n",
        "      user_recommendations[user] = [x[0] for x in top_n[user]]\n",
        "\n",
        "      fem_count = 0\n",
        "      male_count = 0\n",
        "\n",
        "      USA_count = 0\n",
        "      \n",
        "      for rec in user_recommendations[user]:\n",
        "        if country_dict[rec] == \"USA\":\n",
        "          USA_count += 1\n",
        "        if gender_dict[rec] == \"male\":\n",
        "          male_count += 1\n",
        "        elif gender_dict[rec] == \"female\":\n",
        "          fem_count += 1\n",
        "\n",
        "      ratio_USA = USA_count/len(user_recommendations[user])        \n",
        "      gen_dif = (male_count - fem_count)/len(user_recommendations[user])\n",
        "\n",
        "      if user in male_oriented.index:\n",
        "        male_oriented.at[user, \"new_male_female_difference_\"+algo_names[i]] = gen_dif\n",
        "      elif user in female_oriented.index:\n",
        "        female_oriented.at[user, \"new_male_female_difference_\"+algo_names[i]] = gen_dif\n",
        "      else:\n",
        "        diverse.at[user, \"new_male_female_difference_\"+algo_names[i]] = gen_dif\n",
        "\n",
        "      if user in USA_oriented.index:\n",
        "        USA_oriented.at[user, \"new_ratio_USA_\"+algo_names[i]] = ratio_USA\n",
        "      elif user in lowUSA_oriented.index:\n",
        "        lowUSA_oriented.at[user, \"new_ratio_USA_\"+algo_names[i]] = ratio_USA\n",
        "      else:\n",
        "        midUSA_oriented.at[user, \"new_ratio_USA_\"+algo_names[i]] = ratio_USA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fyqKXRG-KX7"
      },
      "source": [
        "# Save files for properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdSjpvRY-NRm"
      },
      "outputs": [],
      "source": [
        "save = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBHdLk-V-Obj",
        "outputId": "22daa9ee-edd8-4093-d09a-997687903930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if save:\n",
        "  from google.colab import drive\n",
        "  import pickle as pkl\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  USA_oriented.to_csv(\"/content/drive/My Drive/new_USA_oriented_100.csv\")\n",
        "  midUSA_oriented.to_csv(\"/content/drive/My Drive/new_midUSA_100.csv\")\n",
        "  lowUSA_oriented.to_csv(\"/content/drive/My Drive/new_lowUSA_oriented_100.csv\")\n",
        "  \n",
        "  female_oriented.to_csv(\"/content/drive/My Drive/new_female_oriented_100.csv\")\n",
        "  diverse.to_csv(\"/content/drive/My Drive/new_diverse_100.csv\")\n",
        "  male_oriented.to_csv(\"/content/drive/My Drive/new_male_oriented_100.csv\")\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAmiq9M1c-9j"
      },
      "source": [
        "# Popularity analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3a0gJqr7-4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d85725-d098-4995-84cb-2be875287a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random model is selected:\n",
            "MostPop model is selected:\n",
            "User-KNN model is selected:\n",
            "MF model is selected:\n",
            "PMF model is selected:\n",
            "BPR model is selected:\n",
            "NMF model is selected:\n",
            "WMF model is selected:\n",
            "PF model is selected:\n",
            "NeuMF model is selected:\n",
            "VAECF model is selected:\n"
          ]
        }
      ],
      "source": [
        "algo_names = ['Random', 'MostPop', 'UserKNN', 'MF', 'PMF', 'BPR', 'NMF', 'WMF', 'PF', 'NeuMF', 'VAECF']\n",
        "\n",
        "i = 0\n",
        "low_rec_gap_list = [] # one entry per algorithmus\n",
        "medium_rec_gap_list = []\n",
        "high_rec_gap_list = []\n",
        "\n",
        "for i in range(0, len(algo_names)):\n",
        "    df_item_dist[algo_names[i]] = 0\n",
        "    low_rec_gap = 0\n",
        "    medium_rec_gap = 0\n",
        "    high_rec_gap = 0\n",
        "    \n",
        "    if algo_names[i] == 'Random':\n",
        "      top_n = get_top_n_random(n=100)\n",
        "    elif algo_names[i] == 'UserKNN':\n",
        "      top_n = get_top_n_UserKNN(n=100)\n",
        "    else:\n",
        "      top_n = get_top_n(algo_names[i], n=100)\n",
        "    low_count = 0\n",
        "    med_count = 0\n",
        "    high_count = 0\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        iid_list = []\n",
        "        for (iid, _) in user_ratings:\n",
        "            df_item_dist.loc[iid, algo_names[i]] += 1\n",
        "            iid_list.append(iid)\n",
        "        gap = sum(df_item_dist[\"count\"].loc[iid_list]) / len(iid_list)\n",
        "        if uid in low_popularity.index:\n",
        "            low_rec_gap += gap\n",
        "            low_count += 1\n",
        "        elif uid in med_popularity.index:\n",
        "            medium_rec_gap += gap\n",
        "            med_count += 1\n",
        "        elif uid in high_popularity.index:\n",
        "            high_rec_gap += gap\n",
        "            high_count += 1\n",
        "    low_rec_gap_list.append(low_rec_gap / low_count)\n",
        "    medium_rec_gap_list.append(medium_rec_gap / med_count)\n",
        "    high_rec_gap_list.append(high_rec_gap / high_count)\n",
        "    i += 1 # next algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buq5Z1f45DhT"
      },
      "source": [
        "## Save files\n",
        "To save:\n",
        "1. df_item_dist\n",
        "2. low_rec_gap_list etc\n",
        "3. exp.result & exp.metric\n",
        "4. training user ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jM6jAdTlwUF"
      },
      "outputs": [],
      "source": [
        "save = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTXH7c-r6G5v",
        "outputId": "124700da-ccd8-41c2-acce-295f90bd5356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "if save:\n",
        "  from google.colab import drive\n",
        "  import pickle as pkl\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  df_item_dist.to_csv(\"/content/drive/My Drive/item_pop_dist\"+addition_1+\"_results_Cornac100.csv\")\n",
        "  with open(\"/content/drive/My Drive/experiment_results_cornac\"+addition_4+\"100.pkl\",\"wb\") as f:\n",
        "    pkl.dump(exp.result,f)\n",
        "  with open(\"/content/drive/My Drive/experiment_metrics_cornac\"+addition_4+\"100.pkl\",\"wb\") as f:\n",
        "    pkl.dump(exp.metrics,f)\n",
        "  with open(\"/content/drive/My Drive/low_rec_gap_list_cornac\"+addition_4+\"100.pkl\",\"wb\") as f:\n",
        "    pkl.dump(low_rec_gap_list,f)\n",
        "  with open(\"/content/drive/My Drive/med_rec_gap_list_cornac\"+addition_4+\"100.pkl\",\"wb\") as f:\n",
        "    pkl.dump(medium_rec_gap_list,f)\n",
        "  with open(\"/content/drive/My Drive/high_rec_gap_list_cornac\"+addition_4+\"100.pkl\",\"wb\") as f:\n",
        "    pkl.dump(high_rec_gap_list,f)\n",
        "  with open(\"/content/drive/My Drive/training_user_ids\"+addition_4+\"_cornac100.pkl\",\"wb\") as f:\n",
        "    pkl.dump(list(rs.train_set.user_ids),f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0Y_YUA0L1G_M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Book recommendation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f80115633d848e2a2a121f0326b55aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfad63423adb40529004a9c3aacbe990",
              "IPY_MODEL_dec6e19cefb74441a093c95f35900108",
              "IPY_MODEL_dc06fabee4394b7aad3f312345a05bff"
            ],
            "layout": "IPY_MODEL_0bae2ea1bf1743e892183934a617c1a3"
          }
        },
        "bfad63423adb40529004a9c3aacbe990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b19eabe09141be965801546342ada7",
            "placeholder": "​",
            "style": "IPY_MODEL_96dc358917fb416e8dc25cb90959ec17",
            "value": "100%"
          }
        },
        "dec6e19cefb74441a093c95f35900108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a808c7adc0c4422d9b80971bbd2c63d1",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dce9af9fe4b14fa59e2c9072aba57ba1",
            "value": 50
          }
        },
        "dc06fabee4394b7aad3f312345a05bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c820e981895c4e5c9482a6c2bbd5f2de",
            "placeholder": "​",
            "style": "IPY_MODEL_0928dacf69c24a31a0b138272eaaa36b",
            "value": " 50/50 [00:00&lt;00:00, 132.81it/s, loss=348561.44]"
          }
        },
        "0bae2ea1bf1743e892183934a617c1a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b19eabe09141be965801546342ada7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96dc358917fb416e8dc25cb90959ec17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a808c7adc0c4422d9b80971bbd2c63d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce9af9fe4b14fa59e2c9072aba57ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c820e981895c4e5c9482a6c2bbd5f2de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0928dacf69c24a31a0b138272eaaa36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}