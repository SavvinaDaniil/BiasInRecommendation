{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdmWUJCl6USJ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SavvinaDaniil/BiasInRecommendation/blob/main/2.%20Book%20Recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZEwzP5d6USR"
      },
      "source": [
        "This notebook should be run on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCeSb4Vu6USS"
      },
      "source": [
        "# Process\n",
        "In this notebook, I will train the book recommendation algorithms using two different packages: <a href=\"http://surpriselib.com/\">Surprise</a> & <a href=\"https://cornac.readthedocs.io/en/latest/\">Cornac</a>. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7QlcgcE6USU"
      },
      "source": [
        "## A. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPmwTeS66USV",
        "outputId": "6d4ee6fd-4263-44af-a714-5d23ec4e9be9",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cornac\n",
            "  Downloading cornac-1.14.2-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 19.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cornac) (1.21.6)\n",
            "Collecting powerlaw\n",
            "  Downloading powerlaw-1.5-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cornac) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from cornac) (4.64.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from powerlaw->cornac) (3.2.2)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from powerlaw->cornac) (1.2.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->powerlaw->cornac) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->powerlaw->cornac) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->powerlaw->cornac) (1.15.0)\n",
            "Installing collected packages: powerlaw, cornac\n",
            "Successfully installed cornac-1.14.2 powerlaw-1.5\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1630140 sha256=3fc70cebff12bf5e1e935a0ef2276edb32bf2b2ba477421ea2ca855f9e3f0c94\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install cornac\n",
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "47V5DR7s6USa"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#from run_algorithms import train_algorithms, train_algorithms_kf, prepare_dataset, prepare_dataset_kf\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "pd.set_option(\"display.precision\", 6)\n",
        "\n",
        "# Cornac imports\n",
        "import cornac\n",
        "from cornac.eval_methods import RatioSplit\n",
        "from cornac.data import Reader as CornacReader #Reader exists in both packages\n",
        "from cornac.models import MostPop, MF, PMF, BPR, NeuMF, WMF, HPF, VAECF, NMF\n",
        "from cornac.models import NMF as CornacNMF #NMF exists in both packages\n",
        "from cornac.metrics import MAE, MSE, RMSE, Precision, Recall, NDCG, AUC, MAP, FMeasure, MRR\n",
        "\n",
        "from surprise import BaselineOnly, KNNBasic, KNNWithMeans, SVDpp, SVD\n",
        "from surprise import NMF as SurpriseNMF #NMF exists in both packages\n",
        "from surprise import Dataset\n",
        "from surprise import Reader as SurpriseReader #Reader exists in both packages\n",
        "from surprise.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from surprise import accuracy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from collections import defaultdict\n",
        "from scipy import stats\n",
        "from numpy.linalg import norm\n",
        "import seaborn as sns\n",
        "# set plot style: grey grid in the background:\n",
        "sns.set(style=\"darkgrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxc749MS6USc"
      },
      "source": [
        "## B. Set hyperparameters\n",
        "There are certain hyperparameters that need to be tuned before the run. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KpDdroKt6USd"
      },
      "outputs": [],
      "source": [
        "item_threshold = 5 # remove users with less than item_threshold items\n",
        "user_threshold = 5 # remove items with less than user_threshold users\n",
        "top_threshold = 200 # remove users who have rated more than top_threshold items\n",
        "recommendation_type = \"books\" # books, music or movies\n",
        "item_col = \"book\" # the item column\n",
        "my_seed = 0 # random_seed\n",
        "top_fraction_items = 0.2 # the limit for an item to be considered popular\n",
        "top_fraction_users = 0.2# the limit for a user to be considered High Mainstriminess\n",
        "split_by = \"pop_fraq\" # sort users by fraction of popular items (pop_fraq) or by average popularity in profile (pop_item_fraq)\n",
        "test_size = 0.2 # the percentage of \"hold out\" data that are used for testing\n",
        "rating_threshold = 1.0 # needed for the cornac library\n",
        "predict_col = \"rating\" # the column we are predicting\n",
        "train_way = \"simple_split\"\n",
        "n_splits = 5 # the amount of splits\n",
        "\n",
        "if train_way == \"simple_split\": n_splits = 1\n",
        "rd.seed(my_seed)\n",
        "np.random.seed(my_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSnYGMbb6USg"
      },
      "source": [
        "These additions will be useful so we can load and save the different files (plots and processed data) with clarity on the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "oYgsM9m86USh"
      },
      "outputs": [],
      "source": [
        "addition_1 = \"_u\"+str(item_threshold)+\"_i\"+str(user_threshold)+\"_t\"+str(top_threshold)\n",
        "addition_2 = addition_1 + \"_tfi\"+str(int(100*top_fraction_items))\n",
        "addition_3 = addition_2 + \"_tfu\"+str(int(100*top_fraction_users))\n",
        "addition_4 = addition_3 + (\"_sbpf\" if (split_by==\"pop_fraq\") else \"_sbpif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbqK-CH56USj"
      },
      "source": [
        "## C. Read files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "utMWqIUK6USk"
      },
      "outputs": [],
      "source": [
        "user_events_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/ratings\"+addition_1+\".csv\"\n",
        "high_user_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/high_users\"+addition_4+\".csv\"\n",
        "low_user_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/low_users\"+addition_4+\".csv\"\n",
        "medium_user_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/med_users\"+addition_4+\".csv\"\n",
        "df_item_dist_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/\"+recommendation_type+\"/item_pop_dist\"+addition_1+\".csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "male_oriented_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/books/high_users_u5_i5_t200_tfu20_mfd.csv\"\n",
        "diverse_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/books/low_users_u5_i5_t200_tfu20_mfd.csv\"\n",
        "female_oriented_file = \"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/books/med_users_u5_i5_t200_tfu20_mfd.csv\""
      ],
      "metadata": {
        "id": "_vg8t_FMIVgV"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "WsWUflDo8K25"
      },
      "outputs": [],
      "source": [
        "low = pd.read_csv(low_user_file, index_col=0)\n",
        "med = pd.read_csv(medium_user_file, index_col=0)\n",
        "high = pd.read_csv(high_user_file, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "male_oriented = pd.read_csv(male_oriented_file, index_col=0)\n",
        "diverse = pd.read_csv(diverse_file, index_col=0)\n",
        "female_oriented = pd.read_csv(female_oriented_file, index_col=0)"
      ],
      "metadata": {
        "id": "AIfIozpLI0KW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTH6eEdX4sw8",
        "outputId": "774491be-7dad-4576-cebf-eaf65e8f442e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6358 6358\n"
          ]
        }
      ],
      "source": [
        "num_users1 = len(low) + len(med) + len(high)\n",
        "num_users2 = len(male_oriented) + len(diverse) + len(female_oriented)\n",
        "print(num_users1, num_users2)\n",
        "num_users = num_users1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "pUKKcoUG81fK"
      },
      "outputs": [],
      "source": [
        "df_item_dist = pd.read_csv(df_item_dist_file, index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_item_dist.index"
      ],
      "metadata": {
        "id": "wVLsu75bjGga",
        "outputId": "efd987a9-63c8-4ee7-a19c-43d206e23897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([ 124,   70,   50,  465,  581,  192,   20,  657,  434,  127,\n",
              "            ...\n",
              "            4510, 4508, 4505, 4500, 4499, 4498, 4497, 4494, 4490, 6920],\n",
              "           dtype='int64', length=6921)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH7BETV86USm"
      },
      "source": [
        "## D. Recommendation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Rm5kOIQMOUa2"
      },
      "outputs": [],
      "source": [
        "# we need two df_item_dist: one for Surprise, one for Cornac\n",
        "df_item_dist_Surprise = df_item_dist.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ctrkzpEGyb0"
      },
      "source": [
        "### Surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGMFHd54JUOh"
      },
      "outputs": [],
      "source": [
        "# df_events = pd.read_csv(user_events_file, low_memory = False, header=0) # create dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmZPcpzaG4dH"
      },
      "outputs": [],
      "source": [
        "# # load dataset in Surprise\n",
        "# reader = SurpriseReader(rating_scale=(df_events[predict_col].min(), df_events[predict_col].max()))\n",
        "# data = Dataset.load_from_df(df_events, reader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxOL9xlVJ27r"
      },
      "outputs": [],
      "source": [
        "# # split in train and test set\n",
        "# trainset, testset = train_test_split(data, test_size = test_size, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6M3o5Z8KMlO"
      },
      "outputs": [],
      "source": [
        "# # select and initialize algorithms\n",
        "# algo_names = [\"Random\",\n",
        "#               \"MostPopular\",\n",
        "#               #'UserItemAvg',\n",
        "#                   'UserKNN',\n",
        "#                   'UserKNNAvg',\n",
        "#                   'NMF', \n",
        "#                   'SVD']\n",
        "\n",
        "# # the default parameters for all algorithms\n",
        "# algos = [] \n",
        "# algos.append(None)#Random())\n",
        "# algos.append(None)#MostPopular())\n",
        "# #algos.append(BaselineOnly()) \n",
        "# algos.append(KNNBasic(sim_options = {'name': 'cosine', 'user_based': True})) \n",
        "# algos.append(KNNWithMeans(sim_options = {'name': 'cosine', 'user_based': True})) \n",
        "# algos.append(SurpriseNMF())\n",
        "# algos.append(SVD())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1t4g_mvPcXB"
      },
      "outputs": [],
      "source": [
        "# def get_top_n_Surprise(predictions, n=10):\n",
        "#     # First map the predictions to each user.\n",
        "#     top_n = defaultdict(list)\n",
        "#     for uid, iid, true_r, est, _ in predictions:\n",
        "#         top_n[uid].append((iid, est))\n",
        "#     # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "#     for uid, user_ratings in top_n.items():\n",
        "#         user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "#         top_n[uid] = user_ratings[:n]\n",
        "#     return top_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EsIyRzKPrGD"
      },
      "outputs": [],
      "source": [
        "# def get_top_n_random_Surprise(testset, df_item_dist, n=10):\n",
        "#     top_n = defaultdict(list)\n",
        "#     for uid, iid, true_r in testset:\n",
        "#       if len(top_n[uid]) == 0:\n",
        "#         for i in range(0, 10):\n",
        "#           top_n[uid].append((rd.choice(df_item_dist.index), i))\n",
        "    \n",
        "#     return top_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMJz96S5Pvja"
      },
      "outputs": [],
      "source": [
        "# def get_top_n_mp_Surprise(testset, item_dist, n=10):\n",
        "#     top_n = defaultdict(list)\n",
        "#     for uid, iid, true_r in testset:\n",
        "#         if len(top_n[uid]) == 0:\n",
        "#             for iid, count in df_item_dist[:n][\"count\"].items():\n",
        "#                 top_n[uid].append((iid, count))\n",
        "#     return top_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2Y5C_k2g810"
      },
      "outputs": [],
      "source": [
        "# trainset_for_testing = trainset.build_anti_testset() + trainset.build_testset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rSoQVlMASti"
      },
      "outputs": [],
      "source": [
        "# len(trainset_for_testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WARtuWfAU92"
      },
      "outputs": [],
      "source": [
        "# trainset2 = trainset.build_anti_testset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSMxxqmhOJi_"
      },
      "outputs": [],
      "source": [
        "# i = 0\n",
        "# low_rec_gap_list = [] # one entry per algorithm\n",
        "# medium_rec_gap_list = []\n",
        "# high_rec_gap_list = []\n",
        "# start = time.time()\n",
        "\n",
        "# for i in tqdm(range(0, len(algo_names))): # for every algorithm\n",
        "#     print(\"~~~~~~~~~~~~~~~~NEW~~~~~~~~~~~~~~~~~\")\n",
        "#     df_item_dist_Surprise[algo_names[i]] = 0 # I am adding a column to Surprise\n",
        "#     low_rec_gap = 0\n",
        "#     medium_rec_gap = 0\n",
        "#     high_rec_gap = 0\n",
        "    \n",
        "#     # get accuracy for personalized approaches\n",
        "#     if algo_names[i] != 'Random' and algo_names[i] != 'MostPopular': # for proper algorithms\n",
        "#         algos[i].fit(trainset) # fit\n",
        "#         predictions = algos[i].test(trainset2) # predict\n",
        "#         print(algo_names[i]) # end of fitting\n",
        "\n",
        "#         #get_mae_of_groups(predictions, low, med, high) TO BE ADDED\n",
        "    \n",
        "#     # get top-n items and calculate gaps for all algorithms\n",
        "#     if algo_names[i] == 'Random':\n",
        "#         top_n = get_top_n_random_Surprise(trainset2, df_item_dist, n=10)\n",
        "#         print(algo_names[i])\n",
        "#     elif algo_names[i] == 'MostPopular':\n",
        "#         top_n = get_top_n_mp_Surprise(trainset2, df_item_dist, n=10)\n",
        "#         print(algo_names[i])\n",
        "#     else:\n",
        "#         top_n = get_top_n_Surprise(predictions, n=10)\n",
        "\n",
        "#     # calculate GAPs\n",
        "#     low_count = 0\n",
        "#     med_count = 0\n",
        "#     high_count = 0\n",
        "#     for uid, user_ratings in top_n.items():\n",
        "#         iid_list = []\n",
        "#         for (iid, _) in user_ratings:\n",
        "#             df_item_dist_Surprise.loc[iid, algo_names[i]] += 1\n",
        "#             iid_list.append(iid)\n",
        "#         gap = sum(df_item_dist_Surprise[\"count\"].loc[iid_list]) / len(iid_list)\n",
        "#         if uid in low.index:\n",
        "#             low_rec_gap += gap\n",
        "#             low_count += 1\n",
        "#         elif uid in med.index:\n",
        "#             medium_rec_gap += gap\n",
        "#             med_count += 1\n",
        "#         elif uid in high.index:\n",
        "#             high_rec_gap += gap\n",
        "#             high_count += 1\n",
        "#     low_rec_gap_list.append(low_rec_gap / low_count)\n",
        "#     medium_rec_gap_list.append(medium_rec_gap / med_count)\n",
        "#     high_rec_gap_list.append(high_rec_gap / high_count)\n",
        "#     i += 1 # next algorithm\n",
        "#     end = time.time()\n",
        "#     print(\"It took \" + str(np.round(end-start)) + \" seconds.\")\n",
        "#     start = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhV-OMlwYIxJ"
      },
      "outputs": [],
      "source": [
        "# Not implemented here yet.\n",
        "# if train_way == \"kfold\":\n",
        "#     for alg in algo_names:\n",
        "#         df_item_dist[alg] = df_item_dist[alg]/n_splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLW_xY3dYYaN"
      },
      "outputs": [],
      "source": [
        "# #len(np.unique([x[0] for x in trainset_for_testing])),\n",
        "# len(np.unique([x[0] for x in testset]))  # unique users\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5ICEtVTikmG"
      },
      "outputs": [],
      "source": [
        "# #len(np.unique([x[1] for x in trainset_for_testing])),\n",
        "# len(np.unique([x[1] for x in testset])) # unique items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNCXpu13bYo1"
      },
      "source": [
        "## Save files\n",
        "To save:\n",
        "1. df_item_dist\n",
        "2. low_rec_gap_list etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6Z7JKwXbYpB"
      },
      "outputs": [],
      "source": [
        "# save = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pGCUO7qbYpF"
      },
      "outputs": [],
      "source": [
        "# if save:\n",
        "#   from google.colab import drive\n",
        "#   import pickle as pkl\n",
        "#   drive.mount('/content/drive')\n",
        "\n",
        "#   df_item_dist_Surprise.to_csv(\"/content/drive/My Drive/item_pop_dist\"+addition_1+\"_results_Surprise.csv\")\n",
        "#   with open(\"/content/drive/My Drive/low_rec_gap_list_Surprise\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "#     pkl.dump(low_rec_gap_list,f)\n",
        "#   with open(\"/content/drive/My Drive/med_rec_gap_list_Surprise\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "#     pkl.dump(medium_rec_gap_list,f)\n",
        "#   with open(\"/content/drive/My Drive/high_rec_gap_list_Surprise\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "#     pkl.dump(high_rec_gap_list,f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe6or3ho6USn"
      },
      "source": [
        "### Cornac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "eMpAQsgL6USo"
      },
      "outputs": [],
      "source": [
        "# load dataset in Cornac\n",
        "os.system(\"wget \"+user_events_file)\n",
        "reader = CornacReader()\n",
        "data = reader.read(user_events_file.split(\"/\")[-1],sep =\",\", skip_lines =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "lZnmi5_l6USo"
      },
      "outputs": [],
      "source": [
        "# Split the data based on ratio\n",
        "rs = RatioSplit(data=data, test_size=test_size, rating_threshold=rating_threshold, seed=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgSd6x89ulGI",
        "outputId": "1c7a3e5b-09f5-4eda-bbae-4fcea5a4154f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6921"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "len([x for x in rs.__dict__[\"train_set\"].item_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "otDvr-GB6USp"
      },
      "outputs": [],
      "source": [
        "# initialize models, here we are comparing: simple, traditional, and neural networks based models\n",
        "models = [\n",
        "          # 1: Random\n",
        "          # 2: MostPop\n",
        "          MostPop(),\n",
        "          # 3: UserKNN\n",
        "          # 4: BPR\n",
        "          BPR(k=10, max_iter=200, learning_rate=0.001, lambda_reg=0.01, seed=123),\n",
        "          # 5: MF\n",
        "          MF(k=30, max_iter=100, learning_rate=0.01, lambda_reg=0.001, seed=123),\n",
        "          # 6: PMF\n",
        "          PMF(k=10, max_iter=100, learning_rate=0.001, lambda_reg=0.001),\n",
        "          # 7: NMF\n",
        "          NMF(k=15, max_iter=50, learning_rate=0.005, lambda_u=0.06, lambda_v=0.06, lambda_bu=0.02, lambda_bi=0.02, use_bias=False, verbose=True, seed=123),\n",
        "          # 8: WMF\n",
        "          WMF(k=50, max_iter=50, learning_rate=0.001, lambda_u=0.01, lambda_v=0.01, verbose=True, seed=123),\n",
        "          # 9: PF\n",
        "          HPF(k=50, seed=123, hierarchical=False, name=\"PF\"),\n",
        "          # 10: NueMF\n",
        "          NeuMF(num_factors=8, layers=[32, 16, 8], act_fn=\"tanh\", num_epochs=1, num_neg=3, batch_size=256, lr=0.001, seed=42, verbose=True),\n",
        "          # 11: VAECF\n",
        "          VAECF(k=10, autoencoder_structure=[20], act_fn=\"tanh\", likelihood=\"mult\", n_epochs=100, batch_size=100, learning_rate=0.001, beta=1.0, seed=123, use_gpu=True, verbose=True)\n",
        "          ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "f79a1d4c01914bfdaf8ace17381f502c",
            "5ea6de414d224665bd115db014388292",
            "c80a008ab6f84248af530f459de8e52d",
            "48c87fcb3bd14803a8b6c2e4914df321",
            "f0bd8be399e249a8a5008fa9085ad7db",
            "3eca9da4a07d4a00b0a3448830c6b3d4",
            "3b7b458cd949462a9642cf18ad62338c",
            "0affb8b8f26841b5bedb68f777504597",
            "20fe1f3e92da4917aa9b973eaf95cabc",
            "b1fdd049a7bc4c8fa52093a834862b24",
            "4ee1f0d7fccd4a09a5cf2e2cdd720bf3",
            "89cb71e115f44b3a8eee209a1a209740",
            "b8680ab892da4c8bad9a5ca6423bba8b",
            "fe698ed14dfc435abecfb4509503f982",
            "15e701518d8b43a881057d12b3fb5f76",
            "5a7a2a3aeb904414965774337cefaec3",
            "6998e14787f045b0bd8c6789ee421e14",
            "7b4ccccd56764e22b40f9be5d255d8d0",
            "33f49558f2b54973b1f2f7d27b6543d3",
            "ad570230e64e4153b06fee045def1a11",
            "46798d8814ef43aabcee4a92ffae4532",
            "0579fe4e6c4f46d59b46ab029963a4e1"
          ]
        },
        "id": "erbjctPK6USq",
        "outputId": "442a60d9-4243-49c7-f1e0-82394f256adc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f79a1d4c01914bfdaf8ace17381f502c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization finished!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89cb71e115f44b3a8eee209a1a209740"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning completed!\n"
          ]
        }
      ],
      "source": [
        "# define metrics to evaluate the models\n",
        "metrics = [MAE(), MSE(), RMSE(), AUC(), MAP(), MRR(), \n",
        "           Precision(k=5), Precision(k=10), Precision(k=20), Precision(k=50),\n",
        "           Recall(k=5), Recall(k=10), Recall(k=20), Recall(k=50),\n",
        "           NDCG(k=5), NDCG(k=10), NDCG(k=20), NDCG(k=50),\n",
        "           FMeasure(k=5), FMeasure(k=10), FMeasure(k=20), FMeasure(k=50)]\n",
        "\n",
        "# put it together in an experiment, voilà!\n",
        "exp = cornac.Experiment(eval_method=rs, models=models, metrics=metrics, user_based=True)\n",
        "exp.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnhS3ZT87sXb"
      },
      "outputs": [],
      "source": [
        "def compute_user_knn(C):\n",
        "  ctime = time.time()\n",
        "  print(\"Training User-based Collaborative Filtering...\", )\n",
        "\n",
        "  sim = C.dot(C.T)\n",
        "  norms = [norm(C[i]) for i in range(C.shape[0])]\n",
        "\n",
        "  for i in tqdm(range(C.shape[0])):\n",
        "    sim[i][i] = 0.0\n",
        "    for j in range(i+1, C.shape[0]):\n",
        "      sim[i][j] /= (norms[i] * norms[j])\n",
        "      sim[j][i] /= (norms[i] * norms[j])\n",
        "\n",
        "  print(\"Done. Elapsed time:\", time.time() - ctime, \"s\")\n",
        "  rec_score = sim.dot(C)\n",
        "  return rec_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr55g2GF7xSl"
      },
      "outputs": [],
      "source": [
        "def read_training_data():\n",
        "  training_matrix = np.zeros((rs.train_set.matrix.shape[0], rs.train_set.matrix.shape[1]))\n",
        "  for uid in tqdm(rs.train_set.uid_map.values()):\n",
        "    for iid in rs.train_set.iid_map.values():\n",
        "      training_matrix[uid, iid] = rs.train_set.matrix[uid, iid]\n",
        "  return training_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7IpeOlm70dg"
      },
      "outputs": [],
      "source": [
        "# creating users-books rating matrix (will be used for User-KNN algorithm)\n",
        "training_matrix = read_training_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw84cfLa2KiH"
      },
      "outputs": [],
      "source": [
        "len(training_matrix), len(training_matrix[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzkJFwrJ72Sy"
      },
      "outputs": [],
      "source": [
        "# running User-KNN algorithms and getting the user-book scores\n",
        "user_knn_scores = compute_user_knn(training_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R-5uOIt74me"
      },
      "outputs": [],
      "source": [
        "# UserKNN recommendation algorithm\n",
        "def get_top_n_UserKNN(n=10):\n",
        "    print(\"User-KNN model is selected:\")\n",
        "    top_n = defaultdict(list)\n",
        "    # test_items = list(rs.test_set.iid_map.keys())\n",
        "    for uid in rs.train_set.uid_map.values():\n",
        "      user_id = list(rs.train_set.user_ids)[uid]\n",
        "      top_n_items_idxs = list(reversed(user_knn_scores[uid].argsort()))[:n]\n",
        "      for iid in top_n_items_idxs:\n",
        "        item_id = list(rs.train_set.item_ids)[iid]\n",
        "        top_n[int(user_id)].append((int(item_id), user_knn_scores[uid][iid]))\n",
        "    return top_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8D7JzdU6PAD"
      },
      "outputs": [],
      "source": [
        "# for model in exp.models:\n",
        "#   print(model.name, len(model.rank(0)[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awd4TmF476qI"
      },
      "outputs": [],
      "source": [
        "def get_top_n(algo_name, n=10):\n",
        "  for model in exp.models:\n",
        "    if model.name == algo_name:\n",
        "      print(model.name + \" model is selected:\")\n",
        "      top_n = defaultdict(list)\n",
        "      for uid in model.train_set.uid_map.values():\n",
        "        user_id = list(model.train_set.user_ids)[uid]\n",
        "        try:\n",
        "          item_rank = model.rank(user_idx=uid)[0] # model.rank: item rank, item_score\n",
        "        except:\n",
        "          item_rank = model.rank(user_idx=int(uid))[0]\n",
        "        # collect top N items\n",
        "        item_rank_top = item_rank[:n]\n",
        "        for iid in item_rank_top:\n",
        "          item_id = list(model.train_set.item_ids)[iid]\n",
        "          top_n[int(user_id)].append((int(item_id), model.score(uid, iid)))\n",
        "  return top_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmssLS8z7883"
      },
      "outputs": [],
      "source": [
        "# random recommendation algorithm\n",
        "def get_top_n_random(n=10):\n",
        "    print(\"Random model is selected:\")\n",
        "    top_n = defaultdict(list)\n",
        "    test_items = list(rs.test_set.iid_map.keys())\n",
        "    for uid in rs.train_set.uid_map.values():\n",
        "      if uid not in top_n.keys():\n",
        "        user_id = list(rs.train_set.user_ids)[uid]\n",
        "        for i in range(0, n):\n",
        "          top_n[int(user_id)].append((int(rd.choice(test_items)), i))\n",
        "    return top_n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gender"
      ],
      "metadata": {
        "id": "oylWDP99cUYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mapped_ratings_with_gender = pd.read_csv(\"https://raw.githubusercontent.com/SavvinaDaniil/BiasInRecommendation/main/data/processed/books/mapped_ratings.csv\", index_col=0)\n",
        "gender_dict = {}\n",
        "for isbn in mapped_ratings_with_gender.ISBN.unique():\n",
        "  gender_dict[isbn] = mapped_ratings_with_gender.gender[mapped_ratings_with_gender.ISBN == isbn].iloc[0]"
      ],
      "metadata": {
        "id": "U_iCRmlAe5sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(gender_dict.keys()) #confirm"
      ],
      "metadata": {
        "id": "XdzRqPubhOoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo_names = ['Random', 'MostPop', 'UserKNN', 'MF', 'PMF', 'BPR', 'NMF', 'WMF', 'PF', 'NeuMF', 'VAECF']\n",
        "\n",
        "i = 0\n",
        "low_rec_gap_list = [] # one entry per algorithmus\n",
        "medium_rec_gap_list = []\n",
        "high_rec_gap_list = []\n",
        "\n",
        "for i in range(0, len(algo_names)):\n",
        "    df_item_dist[algo_names[i]] = 0\n",
        "    male_or_diff = 0\n",
        "    diverse_diff = 0\n",
        "    female_or_diff = 0\n",
        "    \n",
        "    if algo_names[i] == 'Random':\n",
        "      top_n = get_top_n_random(n=10)\n",
        "    elif algo_names[i] == 'UserKNN':\n",
        "      top_n = get_top_n_UserKNN(n=10)\n",
        "    else:\n",
        "      top_n = get_top_n(algo_names[i], n=10)\n",
        "\n",
        "    users = top_n.keys()\n",
        "    user_recommendations = {}\n",
        "    for user in users:\n",
        "      user_recommendations[user] = [x[0] for x in top_n[user]]\n",
        "      for rec in user_recommendations[user]:\n",
        "        print(gender_dict[rec])\n",
        "\n",
        "\n",
        "    break\n",
        "    # low_count = 0\n",
        "    # med_count = 0\n",
        "    # high_count = 0\n",
        "    # for uid, user_ratings in top_n.items():\n",
        "    #     iid_list = []\n",
        "    #     for (iid, _) in user_ratings:\n",
        "    #         df_item_dist.loc[iid, algo_names[i]] += 1\n",
        "    #         iid_list.append(iid)\n",
        "    #     gap = sum(df_item_dist[\"count\"].loc[iid_list]) / len(iid_list)\n",
        "    #     if uid in low.index:\n",
        "    #         low_rec_gap += gap\n",
        "    #         low_count += 1\n",
        "    #     elif uid in med.index:\n",
        "    #         medium_rec_gap += gap\n",
        "    #         med_count += 1\n",
        "    #     elif uid in high.index:\n",
        "    #         high_rec_gap += gap\n",
        "    #         high_count += 1\n",
        "    # low_rec_gap_list.append(low_rec_gap / low_count)\n",
        "    # medium_rec_gap_list.append(medium_rec_gap / med_count)\n",
        "    # high_rec_gap_list.append(high_rec_gap / high_count)\n",
        "    # i += 1 # next algorithm"
      ],
      "metadata": {
        "id": "aQ1uLRRfcWHd",
        "outputId": "dd5a2b4d-13f2-4ccc-f843-e5f4b6339e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random model is selected:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-a235fecdaf1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0muser_recommendations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_recommendations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 11890"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Popularity"
      ],
      "metadata": {
        "id": "jAmiq9M1c-9j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "x3a0gJqr7-4h",
        "outputId": "1ae9f8c3-8d90-4f6a-a3b2-af3ced6ab190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Random model is selected:\n",
            "1\n",
            "MostPop model is selected:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f97d334adae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mtop_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_n_UserKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mtop_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mlow_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmed_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-6b7928b26348>\u001b[0m in \u001b[0;36mget_top_n\u001b[0;34m(algo_name, n)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mitem_rank_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_rank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem_rank_top\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m           \u001b[0mitem_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m           \u001b[0mtop_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "algo_names = ['Random', 'MostPop', 'UserKNN', 'MF', 'PMF', 'BPR', 'NMF', 'WMF', 'PF', 'NeuMF', 'VAECF']\n",
        "\n",
        "i = 0\n",
        "low_rec_gap_list = [] # one entry per algorithmus\n",
        "medium_rec_gap_list = []\n",
        "high_rec_gap_list = []\n",
        "\n",
        "for i in range(0, len(algo_names)):\n",
        "    print(i)\n",
        "    df_item_dist[algo_names[i]] = 0\n",
        "    low_rec_gap = 0\n",
        "    medium_rec_gap = 0\n",
        "    high_rec_gap = 0\n",
        "    \n",
        "    if algo_names[i] == 'Random':\n",
        "      top_n = get_top_n_random(n=10)\n",
        "    elif algo_names[i] == 'UserKNN':\n",
        "      top_n = get_top_n_UserKNN(n=10)\n",
        "    else:\n",
        "      top_n = get_top_n(algo_names[i], n=10)\n",
        "    low_count = 0\n",
        "    med_count = 0\n",
        "    high_count = 0\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        iid_list = []\n",
        "        for (iid, _) in user_ratings:\n",
        "            df_item_dist.loc[iid, algo_names[i]] += 1\n",
        "            iid_list.append(iid)\n",
        "        gap = sum(df_item_dist[\"count\"].loc[iid_list]) / len(iid_list)\n",
        "        if uid in low.index:\n",
        "            low_rec_gap += gap\n",
        "            low_count += 1\n",
        "        elif uid in med.index:\n",
        "            medium_rec_gap += gap\n",
        "            med_count += 1\n",
        "        elif uid in high.index:\n",
        "            high_rec_gap += gap\n",
        "            high_count += 1\n",
        "    low_rec_gap_list.append(low_rec_gap / low_count)\n",
        "    medium_rec_gap_list.append(medium_rec_gap / med_count)\n",
        "    high_rec_gap_list.append(high_rec_gap / high_count)\n",
        "    i += 1 # next algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buq5Z1f45DhT"
      },
      "source": [
        "## Save files\n",
        "To save:\n",
        "1. df_item_dist\n",
        "2. low_rec_gap_list etc\n",
        "3. exp.result & exp.metric\n",
        "4. training user ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jM6jAdTlwUF"
      },
      "outputs": [],
      "source": [
        "save = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTXH7c-r6G5v",
        "outputId": "71b42fd9-5776-4234-a57e-9c6f92e4bff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if save:\n",
        "  from google.colab import drive\n",
        "  import pickle as pkl\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  df_item_dist.to_csv(\"/content/drive/My Drive/item_pop_dist\"+addition_1+\"_results_Cornac.csv\")\n",
        "  with open(\"/content/drive/My Drive/experiment_results_cornac\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(exp.result,f)\n",
        "  with open(\"/content/drive/My Drive/experiment_metrics_cornac\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(exp.metrics,f)\n",
        "  with open(\"/content/drive/My Drive/low_rec_gap_list_cornac\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(low_rec_gap_list,f)\n",
        "  with open(\"/content/drive/My Drive/med_rec_gap_list_cornac\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(medium_rec_gap_list,f)\n",
        "  with open(\"/content/drive/My Drive/high_rec_gap_list_cornac\"+addition_4+\".pkl\",\"wb\") as f:\n",
        "    pkl.dump(high_rec_gap_list,f)\n",
        "  with open(\"/content/drive/My Drive/training_user_ids\"+addition_4+\"_cornac.pkl\",\"wb\") as f:\n",
        "    pkl.dump(list(rs.train_set.user_ids),f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Book recommendation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f79a1d4c01914bfdaf8ace17381f502c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ea6de414d224665bd115db014388292",
              "IPY_MODEL_c80a008ab6f84248af530f459de8e52d",
              "IPY_MODEL_48c87fcb3bd14803a8b6c2e4914df321"
            ],
            "layout": "IPY_MODEL_f0bd8be399e249a8a5008fa9085ad7db"
          }
        },
        "5ea6de414d224665bd115db014388292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eca9da4a07d4a00b0a3448830c6b3d4",
            "placeholder": "​",
            "style": "IPY_MODEL_3b7b458cd949462a9642cf18ad62338c",
            "value": "100%"
          }
        },
        "c80a008ab6f84248af530f459de8e52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0affb8b8f26841b5bedb68f777504597",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20fe1f3e92da4917aa9b973eaf95cabc",
            "value": 50
          }
        },
        "48c87fcb3bd14803a8b6c2e4914df321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1fdd049a7bc4c8fa52093a834862b24",
            "placeholder": "​",
            "style": "IPY_MODEL_4ee1f0d7fccd4a09a5cf2e2cdd720bf3",
            "value": " 50/50 [00:00&lt;00:00, 127.09it/s, loss=358527.66]"
          }
        },
        "f0bd8be399e249a8a5008fa9085ad7db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eca9da4a07d4a00b0a3448830c6b3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b7b458cd949462a9642cf18ad62338c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0affb8b8f26841b5bedb68f777504597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20fe1f3e92da4917aa9b973eaf95cabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1fdd049a7bc4c8fa52093a834862b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ee1f0d7fccd4a09a5cf2e2cdd720bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89cb71e115f44b3a8eee209a1a209740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8680ab892da4c8bad9a5ca6423bba8b",
              "IPY_MODEL_fe698ed14dfc435abecfb4509503f982",
              "IPY_MODEL_15e701518d8b43a881057d12b3fb5f76"
            ],
            "layout": "IPY_MODEL_5a7a2a3aeb904414965774337cefaec3"
          }
        },
        "b8680ab892da4c8bad9a5ca6423bba8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6998e14787f045b0bd8c6789ee421e14",
            "placeholder": "​",
            "style": "IPY_MODEL_7b4ccccd56764e22b40f9be5d255d8d0",
            "value": "100%"
          }
        },
        "fe698ed14dfc435abecfb4509503f982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33f49558f2b54973b1f2f7d27b6543d3",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad570230e64e4153b06fee045def1a11",
            "value": 50
          }
        },
        "15e701518d8b43a881057d12b3fb5f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46798d8814ef43aabcee4a92ffae4532",
            "placeholder": "​",
            "style": "IPY_MODEL_0579fe4e6c4f46d59b46ab029963a4e1",
            "value": " 50/50 [00:24&lt;00:00,  2.05it/s, loss=218]"
          }
        },
        "5a7a2a3aeb904414965774337cefaec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6998e14787f045b0bd8c6789ee421e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4ccccd56764e22b40f9be5d255d8d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33f49558f2b54973b1f2f7d27b6543d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad570230e64e4153b06fee045def1a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46798d8814ef43aabcee4a92ffae4532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0579fe4e6c4f46d59b46ab029963a4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}